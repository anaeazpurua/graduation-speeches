{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec08c455",
   "metadata": {},
   "source": [
    "### Lede Program - Project 2 \n",
    "\n",
    "- What did the most popular commencement speakers said to 2023 graduates?\n",
    "- What words did they use more frequently?\n",
    "- Where there common topics? \n",
    "\n",
    "#### Goals\n",
    "- Practice scrapping\n",
    "- Learn and practice nltk \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf4bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99bbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To decide the top 12 speakers I checked several news articles and chose two to scrape the names\n",
    "#and create a list. \n",
    "#The first list of speakers was published by the Guardian with the headline: \"\"\n",
    "url = (\"https://www.theguardian.com/education/2023/may/31/commencement-speeches-graduation-2023-tom-hanks-oprah-winfrey\")\n",
    "html = requests.get(url).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8e4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8346d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<strong>Patton Oswalt, actor and comedian, William &amp; Mary</strong>,\n",
       " <strong>Isabel Wilkerson, journalist and author, Occidental College</strong>,\n",
       " <strong>Raphael Warnock, Georgia senator, Bard College</strong>,\n",
       " <strong>Tom Hanks, actor, Harvard University</strong>,\n",
       " <strong>Karine Jean-Pierre, White House press secretary, Rice University</strong>,\n",
       " <strong>Sanna Marin, Finnish prime minister, New York University</strong>,\n",
       " <strong>Nikole Hannah-Jones, journalist and author, Spelman College</strong>,\n",
       " <strong>Oprah Winfrey, talkshow host, actor and producer, Tennessee State University</strong>,\n",
       " <strong>Lester Holt, journalist, Villanova University</strong>,\n",
       " <strong>Mae Jemison, astronaut, University of Delaware</strong>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers = soup.select(\"h2 strong\")\n",
    "speakers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f005fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patton Oswalt, actor and comedian, William & Mary\n",
      "Isabel Wilkerson, journalist and author, Occidental College\n",
      "Raphael Warnock, Georgia senator, Bard College\n",
      "Tom Hanks, actor, Harvard University\n",
      "Karine Jean-Pierre, White House press secretary, Rice University\n",
      "Sanna Marin, Finnish prime minister, New York University\n",
      "Nikole Hannah-Jones, journalist and author, Spelman College\n",
      "Oprah Winfrey, talkshow host, actor and producer, Tennessee State University\n",
      "Lester Holt, journalist, Villanova University\n",
      "Mae Jemison, astronaut, University of Delaware\n"
     ]
    }
   ],
   "source": [
    "for speaker in speakers:\n",
    "    print(speaker.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98a74b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>college</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patton Oswalt</td>\n",
       "      <td>William &amp; Mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isabel Wilkerson</td>\n",
       "      <td>Occidental College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raphael Warnock</td>\n",
       "      <td>Bard College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom Hanks</td>\n",
       "      <td>Harvard University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karine Jean-Pierre</td>\n",
       "      <td>Rice University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sanna Marin</td>\n",
       "      <td>New York University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nikole Hannah-Jones</td>\n",
       "      <td>Spelman College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oprah Winfrey</td>\n",
       "      <td>actor and producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lester Holt</td>\n",
       "      <td>Villanova University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mae Jemison</td>\n",
       "      <td>University of Delaware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                  college\n",
       "0        Patton Oswalt           William & Mary\n",
       "1     Isabel Wilkerson       Occidental College\n",
       "2      Raphael Warnock             Bard College\n",
       "3            Tom Hanks       Harvard University\n",
       "4   Karine Jean-Pierre          Rice University\n",
       "5          Sanna Marin      New York University\n",
       "6  Nikole Hannah-Jones          Spelman College\n",
       "7        Oprah Winfrey       actor and producer\n",
       "8          Lester Holt     Villanova University\n",
       "9          Mae Jemison   University of Delaware"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I included the name of the college to facilitate the search for the full transcript. \n",
    "df_guardian = pd.DataFrame([{\n",
    "    \"name\": speaker.text.split(\",\")[0], \n",
    "    \"college\": speaker.text.split(\",\")[2]\n",
    "} for speaker in speakers])\n",
    "\n",
    "df_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6ded94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second list I selected was published by Forbes.\n",
    "url_2 = \"https://www.forbes.com/sites/emmylucas/2023/06/06/the-best-career-advice-from-2023s-top-graduation-speeches/?sh=627d14f04451\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c518ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_2 = requests.get(url_2).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae4c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_2 = BeautifulSoup(html_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03435aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2 class=\"subhead-embed color-accent bg-base font-accent font-size text-align\">Oprah Winfrey</h2>,\n",
       " <h2 class=\"subhead-embed color-accent bg-base font-accent font-size text-align\">Bill Gates</h2>,\n",
       " <h2 class=\"subhead-embed color-accent bg-base font-accent font-size text-align\">Joe Biden</h2>,\n",
       " <h2 class=\"subhead-embed color-accent bg-base font-accent font-size text-align\">Sanna Marin</h2>,\n",
       " <h2 class=\"subhead-embed color-accent bg-base font-accent font-size text-align\">Nikole Hannah-Jones</h2>,\n",
       " <h2 class=\"subhead-embed color-accent bg-base font-accent font-size text-align\">Hamdi Ulukaya</h2>,\n",
       " <h2 class=\"subhead-embed color-accent bg-base font-accent font-size text-align\">Tom Hanks</h2>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers_2 = soup_2.select(\"h2\") \n",
    "speakers_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdbde5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oprah Winfrey\n",
      "Bill Gates\n",
      "Joe Biden\n",
      "Sanna Marin\n",
      "Nikole Hannah-Jones\n",
      "Hamdi Ulukaya\n",
      "Tom Hanks\n"
     ]
    }
   ],
   "source": [
    "for speaker in speakers_2:\n",
    "    print(speaker.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50670716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oprah Winfrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Gates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joe Biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sanna Marin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nikole Hannah-Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hamdi Ulukaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tom Hanks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name\n",
       "0        Oprah Winfrey\n",
       "1           Bill Gates\n",
       "2            Joe Biden\n",
       "3          Sanna Marin\n",
       "4  Nikole Hannah-Jones\n",
       "5        Hamdi Ulukaya\n",
       "6            Tom Hanks"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forbes = pd.DataFrame([{\n",
    "    \"name\": speaker.text.split(\",\")[0], \n",
    "} for speaker in speakers_2])\n",
    "\n",
    "df_forbes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f83218ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>college</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patton Oswalt</td>\n",
       "      <td>William &amp; Mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isabel Wilkerson</td>\n",
       "      <td>Occidental College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raphael Warnock</td>\n",
       "      <td>Bard College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom Hanks</td>\n",
       "      <td>Harvard University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karine Jean-Pierre</td>\n",
       "      <td>Rice University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sanna Marin</td>\n",
       "      <td>New York University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nikole Hannah-Jones</td>\n",
       "      <td>Spelman College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oprah Winfrey</td>\n",
       "      <td>actor and producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lester Holt</td>\n",
       "      <td>Villanova University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mae Jemison</td>\n",
       "      <td>University of Delaware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hamdi Ulukaya</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                  college\n",
       "0         Patton Oswalt           William & Mary\n",
       "1      Isabel Wilkerson       Occidental College\n",
       "2       Raphael Warnock             Bard College\n",
       "3             Tom Hanks       Harvard University\n",
       "4    Karine Jean-Pierre          Rice University\n",
       "5           Sanna Marin      New York University\n",
       "6   Nikole Hannah-Jones          Spelman College\n",
       "7         Oprah Winfrey       actor and producer\n",
       "8           Lester Holt     Villanova University\n",
       "9           Mae Jemison   University of Delaware\n",
       "10           Bill Gates                      NaN\n",
       "11            Joe Biden                      NaN\n",
       "12        Hamdi Ulukaya                      NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I merged the two lists \n",
    "df_guardian.merge(df_forbes, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d0143",
   "metadata": {},
   "source": [
    "## The Speeches -- \n",
    "I need to find the urls and the actual speeches to do the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e575f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of full transcripts. Because I have limited time to finish this project, I decided to focus on the speeches with\n",
    "#full transcripts. I found some of the other speeches in YouTube and actually realized I could copy and paste the \n",
    "#YouTube transcripts when I inspect the page, but I only did it for one speech because I didn't have time!). Another \n",
    "#idea worth exploring in the future is to focus on speeches delivered by Black women. I noticed that at least 6 gave very\n",
    "#inspiring commencement speeches in 2023. It would be great to highlight them. \n",
    "\n",
    "biden_url = \"https://www.whitehouse.gov/briefing-room/speeches-remarks/2023/05/13/remarks-by-president-biden-at-the-howard-university-class-of-2023-commencement-address/\"\n",
    "hanks_url = \"https://www.harvard.edu/media-relations/2023/05/25/tom-hanks-commencement-speech/\"\n",
    "oprah_url = \"https://awpc.cattcenter.iastate.edu/2023/05/09/tennessee-state-university-commencement-address-may-6-2023/\"\n",
    "gates_url = \"https://www.gatesnotes.com/NAU-Commencement-Speech\"\n",
    "marin_url = \"https://valtioneuvosto.fi/en/-//10616/speech-by-prime-minister-sanna-marin-at-the-new-york-university-s-commencement-17.5.2023\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1e1ab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/anaeazpurua/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I'm importing the nltk package to analyze the speeches. Since I had not done this before,\n",
    "# I followed the NLTK documentation plus several tutorials: \n",
    "#1.https://www.youtube.com/watch?v=X2vAabgKiuM --Great because he uses jupyter notebooks and offers a very simple and\n",
    "#yet deep explanation\n",
    "#2.https://realpython.com/nltk-nlp-python/\n",
    "#3.https://towardsdatascience.com/find-common-words-in-article-with-python-module-newspaper-and-nltk-8c7d6c75733\n",
    "#Credits for nltk: Bird, Steven, Edward Loper and Ewan Klein (2009).\n",
    "#Natural Language Processing with Python.  O'Reilly Media Inc.\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f5f1c",
   "metadata": {},
   "source": [
    "## The actual analysis -- first speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f271c356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n<html class=\"no-js alert__has-cookie\" lang=\"en-US\">\\n<head>\\n\\t<meta charset=\"utf-8\">\\n\\t<meta name=\"google\" content=\"notranslate\">\\n\\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\t<link rel=\"profile\" href=\"https://gmpg.org/xfn/11\">\\n\\t\\n\\t<!-- If you\\'re reading this, we need your help building back better. https://usds.gov/ -->\\n<meta name=\\'robots\\' content=\\'index, follow, max-image-preview:large, max-snippet:-1, '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the first speech\n",
    "html_biden = requests.get(biden_url).text\n",
    "html_biden[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bfbf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts it to a beautiful soup object\n",
    "soup_biden = BeautifulSoup(html_biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "810aa981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11:34 A.M. EDT\\xa0THE PRESIDENT:\\xa0 Well, thank you, Mr. President, for that introduction.\\xa0 Dr. Morse, thank you for the incredible honorary degree.\\xa0And thank you, President Frederick, for the invitation and for your leadership of your alma mater.\\xa0Serena — Student Body President, College of Pharmacy, the'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting the text I want to use from the actual speech\n",
    "biden_text = (soup_biden.select(\"section.body-content p\")[1]).text\n",
    "biden_text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd1dec",
   "metadata": {},
   "source": [
    "### Preparing the text - Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "493ad5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to tokenize the text\n",
    "biden_tokens = word_tokenize(biden_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f5c4426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4430"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biden_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8fb50421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to see the most common words or punctuation signs?1?! I need to do some cleaning to analize the speech.\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fd42229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 285, ',': 205, 'the': 183, 'and': 138, '’': 108, 'of': 107, 'to': 104, 'i': 100, 'you': 93, '—': 68, ...})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in biden_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2febb4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 285),\n",
       " (',', 205),\n",
       " ('the', 183),\n",
       " ('and', 138),\n",
       " ('’', 108),\n",
       " ('of', 107),\n",
       " ('to', 104),\n",
       " ('i', 100),\n",
       " ('you', 93),\n",
       " ('—', 68)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequency of top 20 words\n",
    "fdist_top10 = fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "369bafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Many of the most frequent words are not adding any meaning, so I want to remove them with the stop words library.\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a693af38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11:34',\n",
       " 'A.M.',\n",
       " 'EDT',\n",
       " 'PRESIDENT',\n",
       " ':',\n",
       " 'Well',\n",
       " ',',\n",
       " 'thank',\n",
       " ',',\n",
       " 'Mr.',\n",
       " 'President',\n",
       " ',',\n",
       " 'introduction',\n",
       " '.',\n",
       " 'Dr.',\n",
       " 'Morse',\n",
       " ',',\n",
       " 'thank',\n",
       " 'incredible',\n",
       " 'honorary']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_biden = [w for w in biden_tokens if not w.lower() in stop_words]\n",
    "filtered_biden[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ae68649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm also using this to remove unwanted punctuation\n",
    "import re\n",
    "punctuation = re.compile(r'[-._?!—,:;’”()“|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "211834a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "postpunc_biden = []\n",
    "for words in filtered_biden:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word) > 0:\n",
    "        postpunc_biden.append(word.lower()) #I make sure all the words are in lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64539364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1656"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I do len again to check how many words are in the text right now, much less than before\n",
    "len(postpunc_biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "053e2b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am',\n",
       " 'edt',\n",
       " 'president',\n",
       " 'well',\n",
       " 'thank',\n",
       " 'mr',\n",
       " 'president',\n",
       " 'introduction',\n",
       " 'dr',\n",
       " 'morse',\n",
       " 'thank',\n",
       " 'incredible',\n",
       " 'honorary',\n",
       " 'degree',\n",
       " 'thank',\n",
       " 'president',\n",
       " 'frederick',\n",
       " 'invitation',\n",
       " 'leadership',\n",
       " 'alma',\n",
       " 'mater',\n",
       " 'serena',\n",
       " 'student',\n",
       " 'body',\n",
       " 'president',\n",
       " 'college',\n",
       " 'pharmacy',\n",
       " 'class',\n",
       " 'speaker',\n",
       " 'applause',\n",
       " 'remember',\n",
       " 'president',\n",
       " 'united',\n",
       " 'states',\n",
       " 'say',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'waiting',\n",
       " 'room',\n",
       " 'say',\n",
       " 'hello',\n",
       " 'promise',\n",
       " 'say',\n",
       " 'joe',\n",
       " 'right',\n",
       " 'laughter',\n",
       " 'think',\n",
       " 'kidding',\n",
       " 'laughter',\n",
       " 'distinguished',\n",
       " 'faculty',\n",
       " 'staff',\n",
       " 'thank',\n",
       " 'parents',\n",
       " 'families',\n",
       " 'class',\n",
       " 'congratulations',\n",
       " 'way',\n",
       " 'applause',\n",
       " 'way',\n",
       " 'get',\n",
       " 'giving',\n",
       " 'degrees',\n",
       " 'promise',\n",
       " 'coming',\n",
       " 'heart',\n",
       " 'heartache',\n",
       " 'blood',\n",
       " 'sweat',\n",
       " 'tears',\n",
       " 'everything',\n",
       " 'came',\n",
       " 'everything',\n",
       " 'yet',\n",
       " 'come',\n",
       " 'new',\n",
       " 'moment',\n",
       " 'hope',\n",
       " 'possibilities',\n",
       " 'graduates',\n",
       " 'begin',\n",
       " 'mentioned',\n",
       " 'many',\n",
       " 'times',\n",
       " 'tomorrow',\n",
       " 'mother',\n",
       " 'day',\n",
       " 'stand',\n",
       " 'mothers',\n",
       " 'grandmothers',\n",
       " 'stand',\n",
       " 'thank',\n",
       " 'applause',\n",
       " 'come',\n",
       " 'moms',\n",
       " 'rule',\n",
       " 'applause',\n",
       " 'friend',\n",
       " 'friend',\n",
       " 'congressman',\n",
       " 'jim',\n",
       " 'clyburn',\n",
       " 'thing',\n",
       " 'admire',\n",
       " 'jim',\n",
       " 'absolute',\n",
       " 'integrity',\n",
       " 'everything',\n",
       " 'everything',\n",
       " 'man',\n",
       " 'honor',\n",
       " 'applause',\n",
       " 'attended',\n",
       " 'south',\n",
       " 'carolina',\n",
       " 'state',\n",
       " 'university',\n",
       " 'commencement',\n",
       " 'jim',\n",
       " 'received',\n",
       " 'degree',\n",
       " 'earned',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'got',\n",
       " 'chance',\n",
       " 'receive',\n",
       " 'person',\n",
       " 'jim',\n",
       " 'honor',\n",
       " 'join',\n",
       " 'today',\n",
       " 'receive',\n",
       " 'honorary',\n",
       " 'degree',\n",
       " 'great',\n",
       " 'university',\n",
       " 'truly',\n",
       " 'special',\n",
       " 'special',\n",
       " 'join',\n",
       " 'fellow',\n",
       " 'honorees',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 'rowley',\n",
       " 'laughs',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 'know',\n",
       " 'talented',\n",
       " 'laughter',\n",
       " 'thought',\n",
       " 'foreign',\n",
       " 'policies',\n",
       " 'know',\n",
       " 'latin',\n",
       " 'american',\n",
       " 'guy',\n",
       " 'know',\n",
       " 'got',\n",
       " 'talk',\n",
       " 'laughter',\n",
       " 'kidding',\n",
       " 'aside',\n",
       " 'thank',\n",
       " 'strong',\n",
       " 'partner',\n",
       " 'caribbean',\n",
       " 'addressing',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'supporting',\n",
       " 'democracies',\n",
       " 'across',\n",
       " 'western',\n",
       " 'hemisphere',\n",
       " 'also',\n",
       " 'honored',\n",
       " 'person',\n",
       " 'today',\n",
       " 'dr',\n",
       " 'tony',\n",
       " 'allen',\n",
       " 'president',\n",
       " 'home',\n",
       " 'state',\n",
       " '[',\n",
       " 'h',\n",
       " ']',\n",
       " 'bcu',\n",
       " 'delaware',\n",
       " 'state',\n",
       " 'university',\n",
       " 'got',\n",
       " 'politically',\n",
       " 'started',\n",
       " 'applause',\n",
       " 'fortunate',\n",
       " 'tony',\n",
       " 'senate',\n",
       " 'staffer',\n",
       " 'long',\n",
       " 'time',\n",
       " 'got',\n",
       " 'phd',\n",
       " 'distinguished',\n",
       " 'career',\n",
       " 'business',\n",
       " 'became',\n",
       " 'president',\n",
       " 'hbcu',\n",
       " 'tony',\n",
       " 'chairs',\n",
       " 'white',\n",
       " 'house',\n",
       " 'board',\n",
       " 'advisors',\n",
       " 'hbcus',\n",
       " 'designed',\n",
       " 'support',\n",
       " 'advance',\n",
       " 'hbcu',\n",
       " 'excellence',\n",
       " 'lot',\n",
       " 'money',\n",
       " 'applause',\n",
       " 'also',\n",
       " 'proud',\n",
       " 'say',\n",
       " 'first',\n",
       " 'white',\n",
       " 'house',\n",
       " 'formally',\n",
       " 'convene',\n",
       " 'real',\n",
       " 'power',\n",
       " 'divine',\n",
       " 'nine',\n",
       " 'applause',\n",
       " 'oh',\n",
       " 'think',\n",
       " 'kidding',\n",
       " 'joke',\n",
       " 'divine',\n",
       " 'nine',\n",
       " 'seat',\n",
       " 'table',\n",
       " 'definitely',\n",
       " 'hear',\n",
       " 'table',\n",
       " 'first',\n",
       " 'time',\n",
       " 'ever',\n",
       " 'white',\n",
       " 'house',\n",
       " 'permanently',\n",
       " 'folks',\n",
       " 'truly',\n",
       " 'honored',\n",
       " 'howard',\n",
       " 'chartered',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'act',\n",
       " 'congress',\n",
       " 'emancipation',\n",
       " 'civil',\n",
       " 'war',\n",
       " 'founded',\n",
       " 'founded',\n",
       " 'hilltop',\n",
       " 'washington',\n",
       " 'dc',\n",
       " 'mecca',\n",
       " 'mecca',\n",
       " 'applause',\n",
       " 'always',\n",
       " 'promoting',\n",
       " 'excellence',\n",
       " 'leadership',\n",
       " 'truth',\n",
       " 'service',\n",
       " 'really',\n",
       " 'proving',\n",
       " 'ground',\n",
       " 'future',\n",
       " 'leaders',\n",
       " 'science',\n",
       " 'medicine',\n",
       " 'education',\n",
       " 'business',\n",
       " 'faith',\n",
       " 'arts',\n",
       " 'entertainment',\n",
       " 'public',\n",
       " 'service',\n",
       " 'trailblazing',\n",
       " 'intellectuals',\n",
       " 'lawyers',\n",
       " 'doctors',\n",
       " 'first',\n",
       " 'black',\n",
       " 'might',\n",
       " 'say',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'united',\n",
       " 'states',\n",
       " 'america',\n",
       " 'applause',\n",
       " 'say',\n",
       " 'kamala',\n",
       " 'sends',\n",
       " 'love',\n",
       " 'sent',\n",
       " 'clear',\n",
       " 'message',\n",
       " 'today',\n",
       " 'privilege',\n",
       " 'points',\n",
       " 'speaking',\n",
       " 'real',\n",
       " 'hu',\n",
       " 'applause',\n",
       " 'realize',\n",
       " 'going',\n",
       " 'cost',\n",
       " 'home',\n",
       " 'laughter',\n",
       " 'enormous',\n",
       " 'pride',\n",
       " 'university',\n",
       " 'founded',\n",
       " 'verses',\n",
       " 'howard',\n",
       " 'anthem',\n",
       " 'quote',\n",
       " 'reared',\n",
       " 'eastern',\n",
       " 'sky',\n",
       " 'proudly',\n",
       " 'hilltop',\n",
       " 'high…',\n",
       " 'stands',\n",
       " 'truth',\n",
       " 'right',\n",
       " 'sending',\n",
       " 'forth',\n",
       " 'rays',\n",
       " 'light',\n",
       " 'matters',\n",
       " 'matters',\n",
       " 'matters',\n",
       " 'living',\n",
       " 'one',\n",
       " 'consequential',\n",
       " 'moments',\n",
       " 'history',\n",
       " 'fundamental',\n",
       " 'questions',\n",
       " 'stake',\n",
       " 'nation',\n",
       " 'stand',\n",
       " 'believe',\n",
       " 'going',\n",
       " 'help',\n",
       " 'answer',\n",
       " 'questions',\n",
       " 'let',\n",
       " 'take',\n",
       " 'back',\n",
       " 'january',\n",
       " 'stood',\n",
       " 'wilmington',\n",
       " 'delaware',\n",
       " 'train',\n",
       " 'station',\n",
       " 'amtrak',\n",
       " 'carrying',\n",
       " 'folder',\n",
       " 'waiting',\n",
       " 'picked',\n",
       " 'guy',\n",
       " 'named',\n",
       " 'barack',\n",
       " 'obama',\n",
       " 'applause',\n",
       " 'first',\n",
       " 'black',\n",
       " 'man',\n",
       " 'elected',\n",
       " 'president',\n",
       " 'united',\n",
       " 'states',\n",
       " 'join',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'way',\n",
       " 'historic',\n",
       " 'inauguration',\n",
       " 'washington',\n",
       " 'moment',\n",
       " 'extraordinary',\n",
       " 'hope',\n",
       " 'also',\n",
       " 'stood',\n",
       " 'god',\n",
       " 'truth',\n",
       " 'help',\n",
       " 'think',\n",
       " 'another',\n",
       " 'day',\n",
       " 'stood',\n",
       " 'much',\n",
       " 'age',\n",
       " 'got',\n",
       " 'law',\n",
       " 'school',\n",
       " 'public',\n",
       " 'gone',\n",
       " 'work',\n",
       " 'big',\n",
       " 'firm',\n",
       " 'state',\n",
       " 'dr',\n",
       " 'king',\n",
       " 'assassinated',\n",
       " 'parts',\n",
       " 'city',\n",
       " 'parts',\n",
       " 'burned',\n",
       " 'ground',\n",
       " 'conservative',\n",
       " 'governor',\n",
       " 'stationed',\n",
       " 'national',\n",
       " 'guard',\n",
       " 'every',\n",
       " 'corner',\n",
       " 'drawn',\n",
       " 'bayonets',\n",
       " 'months',\n",
       " 'quit',\n",
       " 'became',\n",
       " 'public',\n",
       " 'defender',\n",
       " 'applause',\n",
       " 'used',\n",
       " 'introduce',\n",
       " 'clients',\n",
       " 'noble',\n",
       " 'interview',\n",
       " 'clients',\n",
       " 'wilmington',\n",
       " 'train',\n",
       " 'station',\n",
       " 'arrested',\n",
       " 'east',\n",
       " 'side',\n",
       " 'taken',\n",
       " 'aftermath',\n",
       " 'riots',\n",
       " 'burned',\n",
       " 'wilmington',\n",
       " 'following',\n",
       " 'assassination',\n",
       " 'waiting',\n",
       " 'barack',\n",
       " 'living',\n",
       " 'history',\n",
       " 'time',\n",
       " 'reliving',\n",
       " 'vivid',\n",
       " 'demonstration',\n",
       " 'comes',\n",
       " 'race',\n",
       " 'america',\n",
       " 'hope',\n",
       " 'travel',\n",
       " 'alone',\n",
       " 'shadowed',\n",
       " 'fear',\n",
       " 'violence',\n",
       " 'hate',\n",
       " 'election',\n",
       " 'reelection',\n",
       " 'first',\n",
       " 'black',\n",
       " 'american',\n",
       " 'president',\n",
       " 'hoped',\n",
       " 'fear',\n",
       " 'violence',\n",
       " 'hate',\n",
       " 'significantly',\n",
       " 'losing',\n",
       " 'ground',\n",
       " 'longer',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'became',\n",
       " 'professor',\n",
       " 'university',\n",
       " 'pennsylvania',\n",
       " 'four',\n",
       " 'years',\n",
       " 'charlottesville',\n",
       " 'virginia',\n",
       " 'crazed',\n",
       " 'neonazis',\n",
       " 'angry',\n",
       " 'faces',\n",
       " 'came',\n",
       " 'fields',\n",
       " 'literally',\n",
       " 'torches',\n",
       " 'carrying',\n",
       " 'nazi',\n",
       " 'banners',\n",
       " 'woods',\n",
       " 'fields',\n",
       " 'chanting',\n",
       " 'antisemitic',\n",
       " 'bile',\n",
       " 'heard',\n",
       " 'across',\n",
       " 'europe',\n",
       " '‘',\n",
       " 's',\n",
       " 'something',\n",
       " 'never',\n",
       " 'thought',\n",
       " 'would',\n",
       " 'ever',\n",
       " 'see',\n",
       " 'america',\n",
       " 'accompanied',\n",
       " 'klansmen',\n",
       " 'white',\n",
       " 'supremacists',\n",
       " 'emerging',\n",
       " 'dark',\n",
       " 'rooms',\n",
       " 'remote',\n",
       " 'fields',\n",
       " 'anonymity',\n",
       " 'internet',\n",
       " 'confronting',\n",
       " 'decent',\n",
       " 'americans',\n",
       " 'backgrounds',\n",
       " 'standing',\n",
       " 'way',\n",
       " 'bright',\n",
       " 'light',\n",
       " 'day',\n",
       " 'young',\n",
       " 'woman',\n",
       " 'objecting',\n",
       " 'presence',\n",
       " 'killed',\n",
       " 'hear',\n",
       " 'famous',\n",
       " 'quote',\n",
       " 'asked',\n",
       " 'happened',\n",
       " 'famous',\n",
       " 'quote',\n",
       " 'fine',\n",
       " 'people',\n",
       " 'sides',\n",
       " 'knew',\n",
       " 'joking',\n",
       " 'knew',\n",
       " 'stay',\n",
       " 'engaged',\n",
       " 'get',\n",
       " 'back',\n",
       " 'public',\n",
       " 'life',\n",
       " 'applause',\n",
       " 'say',\n",
       " 'reason',\n",
       " 'say',\n",
       " 'journey',\n",
       " 'tell',\n",
       " 'fearless',\n",
       " 'pro',\n",
       " 'progress',\n",
       " 'towards',\n",
       " 'justice',\n",
       " 'often',\n",
       " 'meets',\n",
       " 'ferocious',\n",
       " 'pushback',\n",
       " 'oldest',\n",
       " 'sinister',\n",
       " 'forces',\n",
       " 'hate',\n",
       " 'never',\n",
       " 'goes',\n",
       " 'away',\n",
       " 'thought',\n",
       " 'graduated',\n",
       " 'could',\n",
       " 'defeat',\n",
       " 'hate',\n",
       " 'never',\n",
       " 'goes',\n",
       " 'away',\n",
       " 'ju',\n",
       " 'hides',\n",
       " 'rocks',\n",
       " 'given',\n",
       " 'oxygen',\n",
       " 'comes',\n",
       " 'rock',\n",
       " 'know',\n",
       " 'truth',\n",
       " 'well',\n",
       " 'silence',\n",
       " 'complicity',\n",
       " 'applause',\n",
       " 'remain',\n",
       " 'silent',\n",
       " 'live',\n",
       " 'battle',\n",
       " 'soul',\n",
       " 'nation',\n",
       " 'still',\n",
       " 'battle',\n",
       " 'soul',\n",
       " 'nation',\n",
       " 'soul',\n",
       " 'nation',\n",
       " 'well',\n",
       " 'believe',\n",
       " 'soul',\n",
       " 'breath',\n",
       " 'life',\n",
       " 'essence',\n",
       " 'soul',\n",
       " 'makes',\n",
       " 'us',\n",
       " 'us',\n",
       " 'soul',\n",
       " 'america',\n",
       " 'makes',\n",
       " 'us',\n",
       " 'unique',\n",
       " 'among',\n",
       " 'nations',\n",
       " 'country',\n",
       " 'founded',\n",
       " 'idea',\n",
       " 'geography',\n",
       " 'religion',\n",
       " 'ethnicity',\n",
       " 'idea',\n",
       " 'sacred',\n",
       " 'proposition',\n",
       " 'rooted',\n",
       " 'scripture',\n",
       " 'enshrined',\n",
       " 'declaration',\n",
       " 'independence',\n",
       " 'created',\n",
       " 'equal',\n",
       " 'image',\n",
       " 'god',\n",
       " 'deserve',\n",
       " 'treated',\n",
       " 'equally',\n",
       " 'throughout',\n",
       " 'lives',\n",
       " 'never',\n",
       " 'fully',\n",
       " 'lived',\n",
       " 'promise',\n",
       " 'never',\n",
       " 'fully',\n",
       " 'walked',\n",
       " 'away',\n",
       " 'know',\n",
       " 'american',\n",
       " 'history',\n",
       " 'always',\n",
       " 'fairytale',\n",
       " 'start',\n",
       " 'constant',\n",
       " 'push',\n",
       " 'pull',\n",
       " 'years',\n",
       " 'best',\n",
       " 'us',\n",
       " 'american',\n",
       " 'ideal',\n",
       " 'create',\n",
       " 'equal',\n",
       " 'worst',\n",
       " 'us',\n",
       " 'harsh',\n",
       " 'reality',\n",
       " 'racism',\n",
       " 'long',\n",
       " 'torn',\n",
       " 'us',\n",
       " 'apart',\n",
       " 'battle',\n",
       " 'never',\n",
       " 'really',\n",
       " 'best',\n",
       " 'days',\n",
       " 'enough',\n",
       " 'us',\n",
       " 'guts',\n",
       " 'hearts',\n",
       " 'st',\n",
       " 'stand',\n",
       " 'best',\n",
       " 'us',\n",
       " 'choose',\n",
       " 'love',\n",
       " 'hate',\n",
       " 'unity',\n",
       " 'disunion',\n",
       " 'progress',\n",
       " 'retreat',\n",
       " 'stand',\n",
       " 'poison',\n",
       " 'white',\n",
       " 'supremacy',\n",
       " 'inaugural',\n",
       " 'address',\n",
       " 'single',\n",
       " 'dangerous',\n",
       " 'terrorist',\n",
       " 'threat',\n",
       " 'homeland',\n",
       " 'white',\n",
       " 'supremacy',\n",
       " 'applause',\n",
       " 'saying',\n",
       " 'black',\n",
       " 'hbcu',\n",
       " 'say',\n",
       " 'wherever',\n",
       " 'go',\n",
       " 'stand',\n",
       " 'truth',\n",
       " 'lies',\n",
       " 'lies',\n",
       " 'told',\n",
       " 'power',\n",
       " 'profit',\n",
       " 'confront',\n",
       " 'ongoing',\n",
       " 'assault',\n",
       " 'subvert',\n",
       " 'elections',\n",
       " 'suppress',\n",
       " 'right',\n",
       " 'vote',\n",
       " 'assault',\n",
       " 'came',\n",
       " 'cast',\n",
       " 'first',\n",
       " 'ballots',\n",
       " '‘',\n",
       " '‘',\n",
       " 'record',\n",
       " 'turnouts',\n",
       " 'delivered',\n",
       " 'historic',\n",
       " 'progress',\n",
       " 'made',\n",
       " 'clear',\n",
       " 'america',\n",
       " 'americans',\n",
       " 'backgrounds',\n",
       " 'obligation',\n",
       " 'call',\n",
       " 'political',\n",
       " 'violence',\n",
       " 'unleashed',\n",
       " 'emboldened',\n",
       " 'mentioned',\n",
       " 'already',\n",
       " 'bomb',\n",
       " 'threats',\n",
       " 'university',\n",
       " 'hbcus',\n",
       " 'across',\n",
       " 'country',\n",
       " 'put',\n",
       " 'democracy',\n",
       " 'ballot',\n",
       " 'reject',\n",
       " 'political',\n",
       " 'extremism',\n",
       " 'reject',\n",
       " 'political',\n",
       " 'violence',\n",
       " 'protect',\n",
       " 'fundamental',\n",
       " 'rights',\n",
       " 'freedoms',\n",
       " 'women',\n",
       " 'choose',\n",
       " 'transgender',\n",
       " 'children',\n",
       " 'free',\n",
       " 'applause',\n",
       " 'affordable',\n",
       " 'healthcare',\n",
       " 'housing',\n",
       " 'applause',\n",
       " 'right',\n",
       " 'raise',\n",
       " 'family',\n",
       " 'retire',\n",
       " 'dignity',\n",
       " 'stand',\n",
       " 'leaders',\n",
       " 'generation',\n",
       " 'give',\n",
       " 'voice',\n",
       " 'people',\n",
       " 'demanding',\n",
       " 'action',\n",
       " 'gun',\n",
       " 'violence',\n",
       " 'expelled',\n",
       " 'state',\n",
       " 'legislative',\n",
       " 'bodies',\n",
       " 'applause',\n",
       " 'stand',\n",
       " 'books',\n",
       " 'banned',\n",
       " 'black',\n",
       " 'history',\n",
       " 'erased',\n",
       " 'applause',\n",
       " 'serious',\n",
       " 'think',\n",
       " 'stand',\n",
       " 'best',\n",
       " 'us',\n",
       " 'today',\n",
       " 'come',\n",
       " 'howard',\n",
       " 'continue',\n",
       " 'work',\n",
       " 'redeem',\n",
       " 'soul',\n",
       " 'nation',\n",
       " 'see',\n",
       " 'future',\n",
       " 'hyperbole',\n",
       " 'finally',\n",
       " 'resolve',\n",
       " 'ongoing',\n",
       " 'questions',\n",
       " 'nation',\n",
       " 'puts',\n",
       " 'strength',\n",
       " 'diversity',\n",
       " 'center',\n",
       " 'american',\n",
       " 'life',\n",
       " 'future',\n",
       " 'celebrates',\n",
       " 'learns',\n",
       " 'history',\n",
       " 'future',\n",
       " 'americans',\n",
       " 'future',\n",
       " 'see',\n",
       " 'leading',\n",
       " 'exaggerating',\n",
       " 'going',\n",
       " 'leading',\n",
       " 'let',\n",
       " 'clear',\n",
       " 'see',\n",
       " 'want',\n",
       " 'future',\n",
       " 'demonize',\n",
       " 'pit',\n",
       " 'people',\n",
       " 'one',\n",
       " 'another',\n",
       " 'anything',\n",
       " 'everything',\n",
       " 'matter',\n",
       " 'desperate',\n",
       " 'immoral',\n",
       " 'hold',\n",
       " 'onto',\n",
       " 'power',\n",
       " 'never',\n",
       " 'going',\n",
       " 'easy',\n",
       " 'battle',\n",
       " 'know',\n",
       " 'oldest',\n",
       " 'sinister',\n",
       " 'forces',\n",
       " 'may',\n",
       " 'believe',\n",
       " 'determine',\n",
       " 'america',\n",
       " 'future',\n",
       " 'wrong',\n",
       " 'applause',\n",
       " 'determine',\n",
       " 'america',\n",
       " 'future',\n",
       " 'determine',\n",
       " 'america',\n",
       " 'future',\n",
       " 'hyperbole',\n",
       " 'graduating',\n",
       " 'class',\n",
       " 'gets',\n",
       " 'choose',\n",
       " 'world',\n",
       " 'graduate',\n",
       " 'every',\n",
       " 'class',\n",
       " 'enters',\n",
       " 'history',\n",
       " 'nation',\n",
       " 'point',\n",
       " 'written',\n",
       " 'others',\n",
       " 'classes',\n",
       " 'every',\n",
       " 'several',\n",
       " 'generations',\n",
       " 'enters',\n",
       " 'point',\n",
       " 'history',\n",
       " 'actually',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'trajectory',\n",
       " 'country',\n",
       " 'face',\n",
       " 'inflection',\n",
       " 'point',\n",
       " 'today',\n",
       " 'know',\n",
       " 'meet',\n",
       " 'moment',\n",
       " 'think',\n",
       " 'many',\n",
       " 'ways',\n",
       " 'already',\n",
       " 'voices',\n",
       " 'votes',\n",
       " 'able',\n",
       " 'fill',\n",
       " 'commitment',\n",
       " 'put',\n",
       " 'first',\n",
       " 'black',\n",
       " 'woman',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'united',\n",
       " 'states',\n",
       " 'america',\n",
       " 'applause',\n",
       " 'way',\n",
       " 'brighter',\n",
       " 'rest',\n",
       " 'laughter',\n",
       " 'one',\n",
       " 'bright',\n",
       " 'woman',\n",
       " 'black',\n",
       " 'women',\n",
       " 'appointed',\n",
       " 'federal',\n",
       " 'appellate',\n",
       " 'courts',\n",
       " 'every',\n",
       " 'president',\n",
       " 'american',\n",
       " 'history',\n",
       " 'combined',\n",
       " 'applause',\n",
       " 'way',\n",
       " 'mean',\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postpunc_biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90ea74f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president',\n",
       " 'well',\n",
       " 'thank',\n",
       " 'mr',\n",
       " 'president',\n",
       " 'introduction',\n",
       " 'dr',\n",
       " 'morse',\n",
       " 'thank',\n",
       " 'incredible',\n",
       " 'honorary',\n",
       " 'degree',\n",
       " 'thank',\n",
       " 'president',\n",
       " 'frederick',\n",
       " 'invitation',\n",
       " 'leadership',\n",
       " 'alma',\n",
       " 'mater',\n",
       " 'serena']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I want to remove all the words \"applause\" and \"laughter\" because they were not part of the speech, but reactions \n",
    "#added to the text by the White House's media department.\n",
    "reactions = [\"applause\", \"laughter\", \"am\", \"edt\"]\n",
    "postpunc_biden1 = []\n",
    "for word in postpunc_biden:\n",
    "    if word not in reactions:\n",
    "        postpunc_biden1.append(word)\n",
    "postpunc_biden1[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "147b61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdistbiden = FreqDist(postpunc_biden1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e1604f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'president': 18, 'america': 16, 'future': 15, 'know': 14, 'say': 13, 'black': 13, 'us': 13, 'stand': 11, 'history': 11, 'way': 9, ...})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistbiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8e0361da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('president', 18),\n",
       " ('america', 16),\n",
       " ('future', 15),\n",
       " ('know', 14),\n",
       " ('say', 13),\n",
       " ('black', 13),\n",
       " ('us', 13),\n",
       " ('stand', 11),\n",
       " ('history', 11),\n",
       " ('way', 9),\n",
       " ('truth', 9),\n",
       " ('think', 8),\n",
       " ('never', 8),\n",
       " ('first', 8),\n",
       " ('going', 8),\n",
       " ('nation', 8),\n",
       " ('see', 8),\n",
       " ('well', 7),\n",
       " ('hope', 7),\n",
       " ('university', 7),\n",
       " ('years', 7),\n",
       " ('american', 7),\n",
       " ('white', 7),\n",
       " ('life', 7),\n",
       " ('soul', 7),\n",
       " ('thank', 6),\n",
       " ('united', 6),\n",
       " ('states', 6),\n",
       " ('promise', 6),\n",
       " ('many', 6),\n",
       " ('state', 6),\n",
       " ('got', 6),\n",
       " ('today', 6),\n",
       " ('also', 6),\n",
       " ('time', 6),\n",
       " ('hbcus', 6),\n",
       " ('howard', 6),\n",
       " ('public', 6),\n",
       " ('one', 6),\n",
       " ('law', 6),\n",
       " ('every', 6),\n",
       " ('violence', 6),\n",
       " ('would', 6),\n",
       " ('people', 6),\n",
       " ('best', 6),\n",
       " ('percent', 6),\n",
       " ('keep', 6),\n",
       " ('class', 5),\n",
       " ('right', 5),\n",
       " ('everything', 5),\n",
       " ('came', 5),\n",
       " ('power', 5),\n",
       " ('vice', 5),\n",
       " ('believe', 5),\n",
       " ('stood', 5),\n",
       " ('god', 5),\n",
       " ('hate', 5),\n",
       " ('americans', 5),\n",
       " ('country', 5),\n",
       " ('student', 4),\n",
       " ('get', 4),\n",
       " ('new', 4),\n",
       " ('day', 4),\n",
       " ('jim', 4),\n",
       " ('change', 4),\n",
       " ('hbcu', 4),\n",
       " ('house', 4),\n",
       " ('excellence', 4),\n",
       " ('ever', 4),\n",
       " ('founded', 4),\n",
       " ('service', 4),\n",
       " ('really', 4),\n",
       " ('leaders', 4),\n",
       " ('light', 4),\n",
       " ('questions', 4),\n",
       " ('help', 4),\n",
       " ('work', 4),\n",
       " ('fear', 4),\n",
       " ('fields', 4),\n",
       " ('standing', 4),\n",
       " ('woman', 4),\n",
       " ('away', 4),\n",
       " ('battle', 4),\n",
       " ('democracy', 4),\n",
       " ('generation', 4),\n",
       " ('give', 4),\n",
       " ('leading', 4),\n",
       " ('debt', 4),\n",
       " ('pass', 4),\n",
       " ('dr', 3),\n",
       " ('degree', 3),\n",
       " ('leadership', 3),\n",
       " ('waiting', 3),\n",
       " ('kidding', 3),\n",
       " ('families', 3),\n",
       " ('come', 3),\n",
       " ('moment', 3),\n",
       " ('ago', 3),\n",
       " ('receive', 3),\n",
       " ('join', 3)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_list = fdistbiden.most_common(100)\n",
    "biden_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20434ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_biden \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(biden_list, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m df_biden_top50 \u001b[38;5;241m=\u001b[39m df_biden[:\u001b[38;5;241m50\u001b[39m]\n\u001b[1;32m      3\u001b[0m df_biden_top50\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_biden = pd.DataFrame(biden_list, columns=['word', 'frequency'])\n",
    "df_biden_top50 = df_biden[:50]\n",
    "df_biden_top50.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1fc534d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biden_top50.to_csv(r'bidentop50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b48f1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization takes into account the morphological analysis of the word. \n",
    "#It maps a several words into one common root, but the output is a proper word. \n",
    "#I wanted to know if this was a more appropiate analysis.\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words_biden = [lemmatizer.lemmatize(word) for word in postpunc_biden1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7aac375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president',\n",
       " 'well',\n",
       " 'thank',\n",
       " 'mr',\n",
       " 'president',\n",
       " 'introduction',\n",
       " 'dr',\n",
       " 'morse',\n",
       " 'thank',\n",
       " 'incredible',\n",
       " 'honorary',\n",
       " 'degree',\n",
       " 'thank',\n",
       " 'president',\n",
       " 'frederick',\n",
       " 'invitation',\n",
       " 'leadership',\n",
       " 'alma',\n",
       " 'mater',\n",
       " 'serena',\n",
       " 'student',\n",
       " 'body',\n",
       " 'president',\n",
       " 'college',\n",
       " 'pharmacy',\n",
       " 'class',\n",
       " 'speaker',\n",
       " 'remember',\n",
       " 'president',\n",
       " 'united']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_words_biden[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f2901b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'president': 18, 'america': 16, 'future': 15, 'know': 14, 'say': 13, 'black': 13, 'u': 13, 'state': 12, 'stand': 12, 'american': 12, ...})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2 = FreqDist(lemmatized_words_biden) \n",
    "fdist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d5bbcf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('president', 18),\n",
       " ('america', 16),\n",
       " ('future', 15),\n",
       " ('know', 14),\n",
       " ('say', 13),\n",
       " ('black', 13),\n",
       " ('u', 13),\n",
       " ('state', 12),\n",
       " ('stand', 12),\n",
       " ('american', 12),\n",
       " ('history', 11),\n",
       " ('way', 10),\n",
       " ('truth', 9),\n",
       " ('nation', 9),\n",
       " ('life', 9),\n",
       " ('right', 8),\n",
       " ('think', 8),\n",
       " ('university', 8),\n",
       " ('year', 8),\n",
       " ('never', 8),\n",
       " ('first', 8),\n",
       " ('going', 8),\n",
       " ('see', 8),\n",
       " ('well', 7),\n",
       " ('hope', 7),\n",
       " ('time', 7),\n",
       " ('white', 7),\n",
       " ('soul', 7),\n",
       " ('thank', 6),\n",
       " ('student', 6),\n",
       " ('class', 6),\n",
       " ('united', 6),\n",
       " ('promise', 6),\n",
       " ('family', 6),\n",
       " ('many', 6),\n",
       " ('day', 6),\n",
       " ('got', 6),\n",
       " ('today', 6),\n",
       " ('also', 6),\n",
       " ('hbcus', 6),\n",
       " ('howard', 6),\n",
       " ('public', 6),\n",
       " ('matter', 6),\n",
       " ('one', 6),\n",
       " ('law', 6),\n",
       " ('every', 6),\n",
       " ('violence', 6),\n",
       " ('would', 6),\n",
       " ('woman', 6),\n",
       " ('people', 6)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10539a4",
   "metadata": {},
   "source": [
    "### Tom Hanks' speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "892005bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<!DOCTYPE html>\\n<html lang=\"en-US\">\\n\\n<head>\\n\\t\\n\\t\\t<meta charset=\"utf-8\"><script type=\"text/javascript\">(window.NREUM||(NREUM={})).init={privacy:{cookies_enabled:true},ajax:{deny_list:[\"bam.nr-data.net\"]}};(window.NREUM||(NREUM={})).loader_config={licenseKey:\"NRJS-415bcf4c4af1a9108ef\",applicationID:\"400299824\"};;/*! For license information please see nr-loader-rum-1.236.0.min.js.LICENSE.txt */\\n(()=>{\"use strict\";var e,t,n={5763:(e,t,n)=>{n.d(t,{P_:()=>f,Mt:()=>p,C5:()=>s,DL:()=>m,OP:()=>_,lF:()=>E'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hanks_url = \"https://www.harvard.edu/media-relations/2023/05/25/tom-hanks-commencement-speech/\"\n",
    "html_hanks = requests.get(hanks_url).text\n",
    "html_hanks[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2f9db626",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_hanks = BeautifulSoup(html_hanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ecfac7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMay 25, 2023\\nAs Prepared for Delivery\\nThank you. On behalf of all of us who have studied for two y'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hanks_text = (soup_hanks.select(\"article\")[0]).text\n",
    "hanks_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ffcd2d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2564"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hanks_tokens = word_tokenize(hanks_text)\n",
    "len(hanks_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b25651af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['May',\n",
       " '25',\n",
       " ',',\n",
       " '2023',\n",
       " 'Prepared',\n",
       " 'Delivery',\n",
       " 'Thank',\n",
       " '.',\n",
       " 'behalf',\n",
       " 'us',\n",
       " 'studied',\n",
       " 'two',\n",
       " 'years',\n",
       " 'Chabot',\n",
       " 'Community',\n",
       " 'College',\n",
       " 'Hayward',\n",
       " ',',\n",
       " 'California',\n",
       " ',',\n",
       " 'two',\n",
       " 'semesters',\n",
       " 'California',\n",
       " 'State',\n",
       " 'University',\n",
       " ',',\n",
       " 'Sacramento',\n",
       " ',',\n",
       " 'forty-five',\n",
       " 'years',\n",
       " 'School',\n",
       " 'Hard',\n",
       " 'Knocks',\n",
       " ',',\n",
       " 'earning',\n",
       " 'Bachelor',\n",
       " 'Arts',\n",
       " 'Degree',\n",
       " 'One-Damn-Thing-After-Another',\n",
       " ',',\n",
       " '–',\n",
       " 'yeah',\n",
       " ',',\n",
       " 'appreciate',\n",
       " ',',\n",
       " 'thank',\n",
       " ',',\n",
       " 'Harvard',\n",
       " ',',\n",
       " 'time…',\n",
       " 'us',\n",
       " 'recite',\n",
       " 'repetition',\n",
       " 'preamble',\n",
       " 'television',\n",
       " 'show',\n",
       " 'might',\n",
       " 'seen',\n",
       " 'five',\n",
       " 'days',\n",
       " 'week',\n",
       " 'strange',\n",
       " 'another',\n",
       " 'planet',\n",
       " 'powers',\n",
       " 'abilities',\n",
       " 'far',\n",
       " 'beyond',\n",
       " 'mortal',\n",
       " 'men',\n",
       " '.',\n",
       " 'Superman',\n",
       " ',',\n",
       " ',',\n",
       " 'disguised',\n",
       " 'mild-mannered',\n",
       " 'reporter',\n",
       " 'great',\n",
       " 'metropolitan',\n",
       " 'newspaper',\n",
       " '–',\n",
       " 'many',\n",
       " 'metropolitan',\n",
       " 'newspapers',\n",
       " ',',\n",
       " 'great',\n",
       " '–',\n",
       " 'could',\n",
       " 'change',\n",
       " 'course',\n",
       " 'mighty',\n",
       " 'rivers',\n",
       " 'bend',\n",
       " 'steel',\n",
       " 'bare',\n",
       " 'hands',\n",
       " '.',\n",
       " 'faster',\n",
       " 'speeding',\n",
       " 'bullet']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_hanks = [w for w in hanks_tokens if not w.lower() in stop_words]\n",
    "filtered_hanks[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "61cfbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation = re.compile(r'[-._?!,:;’”()“–|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d2fa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "postpunc_hanks = []\n",
    "for words in filtered_hanks:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word) > 0:\n",
    "        postpunc_hanks.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a9259cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['may',\n",
       " 'prepared',\n",
       " 'delivery',\n",
       " 'thank',\n",
       " 'behalf',\n",
       " 'us',\n",
       " 'studied',\n",
       " 'two',\n",
       " 'years',\n",
       " 'chabot',\n",
       " 'community',\n",
       " 'college',\n",
       " 'hayward',\n",
       " 'california',\n",
       " 'two',\n",
       " 'semesters',\n",
       " 'california',\n",
       " 'state',\n",
       " 'university',\n",
       " 'sacramento',\n",
       " 'fortyfive',\n",
       " 'years',\n",
       " 'school',\n",
       " 'hard',\n",
       " 'knocks']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postpunc_hanks[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "98e8fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1058"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(postpunc_hanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c31c3e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'truth': 20, 'way': 10, 'american': 9, 'justice': 8, 'right': 7, 'every': 7, 'make': 7, 'time': 6, 'one': 6, 'work': 6, ...})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdisthanks = FreqDist(postpunc_hanks) \n",
    "fdisthanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "03bb1441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('truth', 20),\n",
       " ('way', 10),\n",
       " ('american', 9),\n",
       " ('justice', 8),\n",
       " ('right', 7),\n",
       " ('every', 7),\n",
       " ('make', 7),\n",
       " ('time', 6),\n",
       " ('one', 6),\n",
       " ('work', 6)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hanks_list = fdisthanks.most_common(50)\n",
    "hanks_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64362717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>truth</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>way</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>justice</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  frequency\n",
       "0     truth         20\n",
       "1       way         10\n",
       "2  american          9\n",
       "3   justice          8\n",
       "4     right          7"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hanks = pd.DataFrame(hanks_list, columns=['word', 'frequency'])\n",
    "df_hanks_top50 = df_hanks[:50]\n",
    "df_hanks_top50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4a3fd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hanks_top50.to_csv(r'hankstop50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c7151",
   "metadata": {},
   "source": [
    "### Oprah's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b34a6504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n\\t<head>\\n\\t\\t\\t\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n\\n\\t\\t<meta charset=\"UTF-8\" />\\n\\t\\t<meta name=\"description\" content=\"[May 6, 2023 | Nashville,&nbsp;Tennessee] Good morning!\"/>\\n\\n\\t\\t<meta property=\"og:title\" content=\"Tennessee State University Commencement Address - May 6, 2023\" />\\n\\t\\t<meta property=\"og:description\" content=\"[May 6, 2023 | Nashville,&nbsp;Tennessee] Good morning!\"/>\\n\\t\\t<meta property=\"og:site_name\" content=\"Archives of Wo'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oprah_url = \"https://awpc.cattcenter.iastate.edu/2023/05/09/tennessee-state-university-commencement-address-may-6-2023/\"\n",
    "\n",
    "html_oprah = requests.get(oprah_url).text\n",
    "html_oprah[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5bdde015",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_oprah = BeautifulSoup(html_oprah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0bd12903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGood morning! Oh, my my.\\nFriends, faculty.... Have a seat, y’all. This is your day.\\nFriends, faculty, family and the Tennessee State University class of [shouting] 2023. [cheers and applause]\\nWho says you can't go home again? Cause I'm back. [cheers]\\nDr. Glenda Glover is the reason why I'm here, be\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oprah_text = (soup_oprah.select(\".post-content\")[0]).text\n",
    "oprah_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1bed6df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3082"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oprah_tokens = word_tokenize(oprah_text)\n",
    "len(oprah_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "007e2d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good', 'morning', '!', 'Oh', ',', '.', 'Friends', ',', 'faculty', '....']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_oprah = [w for w in oprah_tokens if not w.lower() in stop_words]\n",
    "filtered_oprah[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2974476e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1674"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_oprah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "56c6c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "postpunc_oprah = []\n",
    "punctuation = re.compile(r'[-._?!,:;’”()“–|0-9]')\n",
    "for words in filtered_oprah:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word) > 0:\n",
    "        postpunc_oprah.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "35d1d7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({\"'s\": 33, \"n't\": 16, 'know': 16, '[': 14, ']': 14, 'one': 14, 'make': 12, \"'m\": 10, 'said': 10, 'tsu': 9, ...})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistoprah = FreqDist(postpunc_oprah) \n",
    "fdistoprah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "21106e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'s\", 33),\n",
       " (\"n't\", 16),\n",
       " ('know', 16),\n",
       " ('[', 14),\n",
       " (']', 14),\n",
       " ('one', 14),\n",
       " ('make', 12),\n",
       " (\"'m\", 10),\n",
       " ('said', 10),\n",
       " ('tsu', 9),\n",
       " ('get', 9),\n",
       " ('right', 9),\n",
       " ('tell', 9),\n",
       " (\"'ve\", 8),\n",
       " ('come', 8),\n",
       " ('father', 8),\n",
       " ('voice', 8),\n",
       " ('day', 7),\n",
       " ('back', 7),\n",
       " ('going', 7),\n",
       " ('time', 7),\n",
       " ('would', 7),\n",
       " ('need', 7),\n",
       " ('life', 7),\n",
       " ('world', 7),\n",
       " ('dream', 7),\n",
       " ('winfrey', 6),\n",
       " ('mr', 6),\n",
       " ('cox', 6),\n",
       " ('like', 6),\n",
       " ('ever', 6),\n",
       " ('always', 6),\n",
       " ('still', 6),\n",
       " ('good', 5),\n",
       " ('family', 5),\n",
       " ('tennessee', 5),\n",
       " ('class', 5),\n",
       " ('go', 5),\n",
       " ('many', 5),\n",
       " ('every', 5),\n",
       " (\"'d\", 5),\n",
       " ('got', 5),\n",
       " ('call', 5),\n",
       " ('chris', 5),\n",
       " ('let', 5),\n",
       " ('god', 5),\n",
       " (\"'ll\", 5),\n",
       " ('person', 5),\n",
       " ('us', 5),\n",
       " ('small', 5)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistoprah.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4d3dc058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'morning',\n",
       " 'oh',\n",
       " 'friends',\n",
       " 'faculty',\n",
       " 'seat',\n",
       " 'day',\n",
       " 'friends',\n",
       " 'faculty',\n",
       " 'family',\n",
       " 'tennessee',\n",
       " 'state',\n",
       " 'university',\n",
       " 'class',\n",
       " 'shouting',\n",
       " 'says',\n",
       " 'go',\n",
       " 'home',\n",
       " 'cause',\n",
       " 'back']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_words = [\"applause\", \"cheers\",\"'s\",\"'ll\", \"'d\", \"'ve\", \"n't\", \"[\", \"]\", \"ca\", \"'m\"]\n",
    "oprah_list = []\n",
    "for word in postpunc_oprah:\n",
    "    if word not in random_words:\n",
    "       oprah_list.append(word)\n",
    "oprah_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4dbbbe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'know': 16, 'one': 14, 'make': 12, 'said': 10, 'tsu': 9, 'get': 9, 'right': 9, 'tell': 9, 'come': 8, 'father': 8, ...})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(oprah_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0c5c63c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('know', 16),\n",
       " ('one', 14),\n",
       " ('make', 12),\n",
       " ('said', 10),\n",
       " ('tsu', 9),\n",
       " ('get', 9),\n",
       " ('right', 9),\n",
       " ('tell', 9),\n",
       " ('come', 8),\n",
       " ('father', 8),\n",
       " ('voice', 8),\n",
       " ('day', 7),\n",
       " ('back', 7),\n",
       " ('going', 7),\n",
       " ('time', 7),\n",
       " ('would', 7),\n",
       " ('need', 7),\n",
       " ('life', 7),\n",
       " ('world', 7),\n",
       " ('dream', 7),\n",
       " ('winfrey', 6),\n",
       " ('mr', 6),\n",
       " ('cox', 6),\n",
       " ('like', 6),\n",
       " ('ever', 6),\n",
       " ('always', 6),\n",
       " ('still', 6),\n",
       " ('good', 5),\n",
       " ('family', 5),\n",
       " ('tennessee', 5),\n",
       " ('class', 5),\n",
       " ('go', 5),\n",
       " ('many', 5),\n",
       " ('every', 5),\n",
       " ('got', 5),\n",
       " ('call', 5),\n",
       " ('chris', 5),\n",
       " ('let', 5),\n",
       " ('god', 5),\n",
       " ('person', 5),\n",
       " ('us', 5),\n",
       " ('small', 5),\n",
       " ('next', 5),\n",
       " ('friends', 4),\n",
       " ('home', 4),\n",
       " ('school', 4),\n",
       " ('united', 4),\n",
       " ('glad', 4),\n",
       " ('start', 4),\n",
       " ('nashville', 4)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistoprah2 = FreqDist(oprah_list) \n",
    "oprah_list2 = fdistoprah2.most_common(50)\n",
    "oprah_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd301427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>make</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tsu</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>right</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tell</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>come</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>father</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  frequency\n",
       "0    know         16\n",
       "1     one         14\n",
       "2    make         12\n",
       "3    said         10\n",
       "4     tsu          9\n",
       "5     get          9\n",
       "6   right          9\n",
       "7    tell          9\n",
       "8    come          8\n",
       "9  father          8"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oprah = pd.DataFrame(oprah_list2, columns=['word', 'frequency'])\n",
    "df_oprah.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "31dd5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oprah.to_csv(r'oprahtop50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d338a923",
   "metadata": {},
   "source": [
    "## Bill Gates' speech \n",
    "gates_url = https://www.gatesnotes.com/NAU-Commencement-Speech -- In the case of this speech, it was easier to copy and paste the text than to scrape it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "09da7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gates_text = \"\"\"Northern Arizona University Commencement Ceremony for the College of Engineering, Informatics, and Applied Sciences and the College of the Environment, Forestry, and Natural Sciences\n",
    "\n",
    "Good afternoon! Thank you, President Cruz Rivera and the Arizona Board of Regents, for this tremendous honor. I am thrilled to be here with NAU’s esteemed faculty and staff.\n",
    "\n",
    "Friends and family, the time has finally come to exhale. Today is your accomplishment, too—and I think that deserves a round of applause.\n",
    "\n",
    "Graduates, you made it. You finished your capstones and your internships. You survived junior-level writing class and multiple Tequila Sunrises. You had your last Dimes Night at Museum Club, and you earned your rubber duck from Collins.\n",
    "\n",
    "You might be happy to know that I have joined your ranks. I am now the proud recipient of an honorary doctorate and an honorary ducky.\n",
    "\n",
    "I am honored to have the opportunity to address you today, because I believe more people should know about the tremendous value of an NAU education. You are graduating from an institution that creates opportunity, fosters innovation, and builds community, and it has prepared you to find solutions to some of the biggest problems facing us today. \n",
    "\n",
    "NAU is also giving you something I never received: A real college degree.\n",
    "\n",
    "Some of you might know that I never made it to my own graduation. I left after three semesters to start Microsoft. So, what does a college dropout know about graduation? Not much personally, to be honest.\n",
    "\n",
    "As I prepared for today, I thought about how you, as new graduates, can have the biggest impact on the world with the education you received here. That led me to thinking about the graduation I never had, the commencement speech I never heard, and the advice I wasn’t given on a day just like this one.\n",
    "\n",
    "That is what I want to share with you this afternoon: The five things I wish I was told at the graduation I never attended.\n",
    "\n",
    "The first thing is, your life isn’t a one-act play.\n",
    "\n",
    "You probably feel a lot of pressure right now to make the right decisions about your career. It might feel like those decisions are permanent. They’re not. What you do tomorrow—or for the next ten years—does not have to be what you do forever.\n",
    "\n",
    "When I left school, I thought I would work at Microsoft for the rest of my life.\n",
    "\n",
    "Today, I still love my work on software, but philanthropy is my full-time job. I spend my days working to create innovations that fight climate change and reduce inequalities around the world—including in health and education.\n",
    "\n",
    "I feel lucky that our foundation gets to support amazing institutions like NAU—even if it’s not what I imagined I’d be doing when I was 22. Not only is it okay to change your mind or have a second career… it can be a very good thing.\n",
    "\n",
    "The second piece of advice I wish I heard at my graduation is that you are never too smart to be confused.\n",
    "\n",
    "I thought I knew everything I needed to know when I left college. But the first step to learning something new is embracing what you don’t know, instead of focusing on what you do know.\n",
    "\n",
    "At some point in your career, you will find yourself facing a problem you cannot solve on your own. When that happens, don’t panic. Take a breath. Force yourself to think things through. And then find smart people to learn from.\n",
    "\n",
    "It could be a colleague with more experience. It could be one of your fellow graduates, who has a good perspective and will push you to think differently. It could be an expert in the field who is willing to reply to your questions over DM.\n",
    "\n",
    "Just about everything I have accomplished came because I sought out others who knew more. People want to help you. The key is to not be afraid to ask.\n",
    "\n",
    "You may be done with school. But you can—and should—see the rest of your life as an education.  \n",
    "\n",
    "My third piece of advice is to gravitate toward work that solves an important problem.\n",
    "\n",
    "The good news is, you are graduating at a time when there are many important problems to solve. New industries and companies are emerging every day that will allow you to make a living and make a difference, and advances in science and technology have made it easier than ever to make a big impact.\n",
    "\n",
    "For example, many of you are becoming foresters. Your professors taught you about cutting-edge tools, like drones that use LIDAR to produce accurate maps of the forest floor. You could find new ways to use that technology to help fight climate change.\n",
    "\n",
    "Some of you are heading off to start careers as programmers. You could use your talents to make sure all people can benefit from artificial intelligence—or to help eliminate biases in AI.\n",
    "\n",
    "When you spend your days doing something that solves a big problem, it energizes you to do your best work. It forces you to be more creative, and it gives your life a strong sense of purpose.\n",
    "\n",
    "My fourth piece of advice is simple: Don’t underestimate the power of friendship.\n",
    "\n",
    "When I was in school, I became friends with another student who shared a lot of my interests, like science fiction novels and computer magazines.\n",
    "\n",
    "Little did I know how important that friendship would be. My friend’s name was Paul Allen—and we started Microsoft together.\n",
    "\n",
    "Remember that people you’ve sat next to in lectures, skied Snowbowl with, and competed against on Wingo night are not just your classmates. They are your network. Your future co-founders and colleagues. A great future source of support, information, and advice.  \n",
    "\n",
    "The only thing more valuable than what you walk offstage with today is who you walk onstage with.\n",
    "\n",
    "My last piece of advice is the one I could have used the most. It took me a long time to learn. And it is this: You are not a slacker if you cut yourself some slack.\n",
    "\n",
    "When I was your age, I didn’t believe in vacations. I didn’t believe in weekends. I pushed everyone around me to work very long hours. In the early days of Microsoft, my office overlooked the parking lot—and I would keep track of who was leaving early and staying late.\n",
    "\n",
    "But as I got older—and especially once I became a father—I realized there is more to life than work.\n",
    "\n",
    "Don’t wait as long as I did to learn this lesson. Take time to nurture your relationships, to celebrate your successes, and to recover from your losses.\n",
    "\n",
    "Take a break when you need to. Take it easy on the people around you when they need it, too.\n",
    "\n",
    "And before you begin the next stage of your lives, take a moment and have some fun. Tonight, this weekend, this summer, whenever. You deserve it.\n",
    "\n",
    "Class of 2023, the future belongs to you. I believe you will be the ones to solve the climate crisis and reduce the gap between the rich and poor.\n",
    "\n",
    "You have already made history by attending college during some truly unprecedented times. I have no doubt that you will continue to make history throughout the rest of your lives. I cannot wait to see how you will drive progress around the world.\n",
    "\n",
    "Congratulations on reaching this momentous milestone. Go Lumberjacks!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "512445e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1402"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gates_tokens = word_tokenize(gates_text)\n",
    "len(gates_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58b119d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['northern',\n",
       " 'arizona',\n",
       " 'university',\n",
       " 'commencement',\n",
       " 'ceremony',\n",
       " 'for',\n",
       " 'the',\n",
       " 'college',\n",
       " 'of',\n",
       " 'engineering']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postpunc_gates = []\n",
    "punctuation = re.compile(r'[-._?!,:;’”()“–|0-9]')\n",
    "for words in gates_tokens:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word) > 0:\n",
    "        postpunc_gates.append(word.lower())\n",
    "postpunc_gates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7dc2d9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['northern',\n",
       " 'arizona',\n",
       " 'university',\n",
       " 'commencement',\n",
       " 'ceremony',\n",
       " 'college',\n",
       " 'engineering',\n",
       " 'informatics',\n",
       " 'applied',\n",
       " 'sciences']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_gates = [w for w in postpunc_gates if not w.lower() in stop_words]\n",
    "filtered_gates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1b6daa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('know', 8),\n",
       " ('college', 6),\n",
       " ('today', 6),\n",
       " ('people', 6),\n",
       " ('never', 6),\n",
       " ('advice', 6),\n",
       " ('make', 6),\n",
       " ('work', 6),\n",
       " ('could', 6),\n",
       " ('graduation', 5)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistgates = FreqDist(filtered_gates) \n",
    "gates_list = fdistgates.most_common(50)\n",
    "gates_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ec780d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>college</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>never</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>advice</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>make</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>work</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>could</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>graduation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  frequency\n",
       "0        know          8\n",
       "1     college          6\n",
       "2       today          6\n",
       "3      people          6\n",
       "4       never          6\n",
       "5      advice          6\n",
       "6        make          6\n",
       "7        work          6\n",
       "8       could          6\n",
       "9  graduation          5"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gates = pd.DataFrame(gates_list, columns=['word', 'frequency'])\n",
    "df_gates.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0b87088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gates.to_csv(r'gatestop50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddbc288",
   "metadata": {},
   "source": [
    "### Prime Minister Sanna Marin\n",
    "marin_url = https://valtioneuvosto.fi/en/-//10616/speech-by-prime-minister-sanna-marin-at-the-new-york-university-s-commencement-17.5.2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "716ae221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n<html class=\"ltr\" dir=\"ltr\" lang=\"en-US\">\\n <head> \\n  <link rel=\"alternate\" hreflang=\"en\" href=\"https://valtioneuvosto.fi/en/-//10616/speech-by-prime-minister-sanna-marin-at-the-new-york-university-s-commencement-17.5.2023\"> \\n  <link rel=\"alternate\" hreflang=\"fi\" href=\"https://valtioneuvosto.fi/-//10616/speech-by-prime-minister-sanna-marin-at-the-new-york-university-s-commencement-17.5.2023\"> \\n  <title>Speech by Prime Minister Sanna Marin at the New York University commencement on'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#html_marin = requests.get(marin_url).text\n",
    "#html_marin[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1681bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup_marin = BeautifulSoup(html_marin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "aca6e294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Speech by Prime Minister Sanna Marin at the New York University commencement on 17 May 2023 \\n\\n\\n Government Communications Department  \\n\\n\\nPublication date \\n17.5.2023\\n 19.20\\n\\n\\nSpeech\\n\\n\\n\\n\\n\\n Prime Minister Sanna Marin spoke at the New York University commencement in New York City on 17 May 2023. Thank you and most importantly: My warmest congratulations to the magnificent graduating class of 2023 from New York University! It is truly an honor to be present here on this prestigious occasion at NYU,'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#marin_text = soup_marin.select(\".media-item\")[0].text\n",
    "#marin_text[:500] -- I tried to scrape the website but couldn't figure out how to only get the text of the speech \n",
    "#within <span itemprop = \"articleBody\">, if I tried .articleBody, it came back empty []\". Because of the deadline, ç\n",
    "#I decided to copy and paste the text, but I'd like to find out how to do this for futute assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "705f0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "marin_text = \"\"\"Thank you and most importantly: My warmest congratulations to the magnificent graduating class of 2023 from New York University!It is truly an honor to be present here on this prestigious occasion at NYU, which has cultivated so many thinkers, writers, scientists and notable alumni. I would also like to express my heartfelt gratitude to the esteemed members of the faculty and to the proud parents and family members as well as devoted friends in attendance. I want to say thank you to President Andrew Hamilton, Board of Trustees Chairman William Berkley, all the trustees, and the esteemed faculty who have all played a vital role in making this day possible.I am deeply grateful to receive this honorary degree and I am very proud to share this occasion with my fellow honorary doctorates Carolyn Bertozzi, Misty Copeland and Freeman Hrabowski, who inspire me with their contributions to our world. Most importantly I am deeply humbled to be among you all today as we celebrate the achievements and graduation of NYU's class of 2023.My dear graduates,What can I say to you on this special day? Today is your graduation day, and the day when you close one chapter of your life and begin a new one. It is a turning point, a day of change. This is why I thought it might be a good day to talk about change – and to approach this theme through my own experiences.Ever since I was elected as the youngest prime minister in the world at the age of 34, I have repeatedly been asked two questions. Both are related to change.The first question is: Did you always want to become prime minister?The second question: How did you do it?I will now reflect on my own answers and share some thoughts to prepare you to when you are asked similar questions in the future.My answer to the first question is no – at a young age I didn’t plan to become a politician or prime minister.The answer to the second question is that I eventually did because I wanted to change things, to change the world. And because I realized that it was also my responsibility, not someone elses.I know you have already been lectured a lot, since you were able to graduate from this very special institution, but I thought I might add to that by offering just a few small insights more.This is why I want to give you three pieces of advice about change.Advice number one: You have the right to want things and to want things to change.Advice number two: Wanting is not enough. To change things, You have to take over. And advice number three: You have to stop being afraid.My first piece of advice is about wanting things to change.When I was in my early twenties, like many of you now, I started to feel passionately about politics. Not about the decision-making system, not about the idea of being an elected politician.I started to feel a passion for issues such as climate change, loss of biodiversity, human rights and the rights of minorities, gender equality and social justice. Things that I saw around me that I wanted to change.I’m sure that many of you here today can relate to that feeling.Coming from a rainbow family I wanted to see a society where everyone could love whomever they wanted. I wanted to see renewed legislation on equal marriage and ensure human rights for all genders. I wanted to close the gender pay gap, and I wanted to see parents, mothers and fathers, to share their family leave more equally so that women could follow their career ambitions same as men.Coming from Finland, a Northern European country with extraordinary nature, I wanted to stop climate change and see the societies become more sustainable. I wanted to see a transition towards carbon neutrality and I wanted to end the destruction of our environment.I wanted a society where everyone would have equal rights and opportunities. I wanted to strengthen the education system so that every child could pursue their dreams. Wanting these changes was what made me join my political party and run in elections. No change can happen without the will.This is why my first advice to you today is that you are allowed to want things. And you need to want things to change for better.Dear class of 2023,My second piece of advice to you today is that it is also your responsibility to take over. The world is as complex as ever. Geopolitical changes going on in the world are questioning the values we believe in. Climate change and biodiversity loss are a threatening our very existence. Digitalization and the development of artificial intelligence are about to bring revolutionary changes to our societies.These are challenges that need to be solved. And there is no one else to do that, other than you.For decades, we have lived in a world with an optimistic expectation of progress.  We have expected our values such as freedom of speech, rule of law, gender equality and democracy to bloom hand in hand with the expansion of free market economy. We thought that globalization and growth would be enough to benefit everyone. We expected to see less authoritarian rule, more respect for diversity and a better world that does not discriminate against people based on their skin tone, gender, sexual orientation or religion. We have expected the freedom of information and the internet to broaden everyone’s understanding.But the history did not end. Freedom of speech and other true elements of democracy are being questioned and limited all over the world. Whether this means diminishing the truth with false balance or using our personal data to influence our democratic elections, the rule of law as well as freedom of expression and the media need active defending.Gender equality has taken leaps backwards across the globe. The right to safe abortion is being limited also in Europe. Different expressions of gender are being presented as a threat.The swollen amount of inequality and a lack of social mobility are challenging our ideas about everyone having the same possibilities and freedoms in life.The tip of the iceberg of all of these worrying developments is the return of war and heavy power politics to the western sphere - to Europe. Russia has broken the rules of the international order we set up together after the world wars by brutally and illegally attacking Ukraine – and in doing so, it has questioned all of the other rules as well.All of these questions are battles of values. And we all must take a side in that battle. There is no middle ground.Combatting climate change and biodiversity loss cannot wait for more stable times. You need to take over to solve them.Problems caused by global warming such as extreme weather conditions, rising sea levels, food shortages, and the disappearance of ecosystems affect all areas of life and truly threaten the well-being of future generations. Similarly, declining of biodiversity can lead to an imbalance in ecosystems, which in turn can accelerate climate change and other environmental disasters.Stopping climate change and loss of biodiversity are essential for the environment, the economy, and people's health. It is clear that combating climate change also requires international cooperation and sharing of responsibility among all states in a fair manner. Building our future growth can be part of the solution. You have all the skills to change the future by pioneering in green technologies and digitalization. This creates not only sustainable growth, but also innovations that can be replicated in all corners of the world.I am sure you know much better than me how digitalization, the development of artificial intelligence and quantum sciences are about to bring revolutionary changes to our societies.Yesterday I had the amazing privilege of visiting NYU’s Tandon Campus in Brooklyn.Seeing the most advanced science, innovation and teaching they do there made it even more evident that the new technologies will define our societies in the near future. At the same time we need amazingly talented people like you to make sure that this technology and these digital solutions are benefitting everyone.New technology has revolutionized people's lives in many ways, but their development also brings new challenges, such as privacy protection. AI-based systems, for example, are often dependent on a large amount of personal data. At the same time, they may reproduce discriminatory structures that exist elsewhere in society. They can also be misused for surveillance purposes, among other things.The global competition for standards and values such as individual freedom and security behind quantum computing, artificial intelligence, and 6G networks is already on its way. And you need to step up to take part in this debate.This, dear graduates, is the present and the future. And it is your responsibility to make sure that the change is on the right track.And you know what? You can.If you believe that the system and the whole world has to be reformed into being more democratic, more equal for all genders and groups, more supportive of freedom of expression – you can make that happen.If you want to influence global warming and save ecosystems, you can.If you want to build new technology, and artificial intelligence that works for the benefit of all in an ethical and sustainable way – you can!My third piece of advice to you, dear graduates, is about how.When I look back at my youth and career, I can see that actually one of the most significant things holding people back is fear. Sometimes it’s the fear of not knowing enough.It might be fear of embarrassment, fear of mistakes, fear of being wrong.It might be fear of not fitting in or fear of not meeting the expectations of others.It might be fear of being declared unworthy because of the way you look or talk and the way you express yourself.Luckily - and unfortunately - there is no superior authority in this world giving us permissions to be ourselves and to step forward to change the world.If I had waited for a permission from others to take my stands, I would still be waiting for that permission.This is why my key advice to you today is not actually an advice but a task:Stop being afraid.My dear class of 2023,When you walk out of this stadium today, I want you to remember these three things.You have to want things to change.It is your turn to take over. And most importantly: Don’t be afraid. You are enough. You are capable.Together with others you can do anything and you must, because there is no one else to do it but you.Dear class,Why am I telling you this? Why am I giving this advise to you? Because there are not nearly enough women in leadership positions. Not nearly enough young people. Not enough people from different backgrounds in our democratic decision making systems.The face of power is not the same as the face of the people. And this has to change. I also want things to change but I can not do it alone. I need you and others with me to make the world more equal, more sustainable and more just. I know I’m not alone with this thought. I know many of you want the same and together we can make it a reality.So now we just have to do it.Dear class,I am so happy to be here in New York with you today. One of the greatest and most progressive cities in the world.And once again: My warmest congratulations to the magnificent graduating class of 2023 from New York University!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e1fd5788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2108"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marin_tokens = word_tokenize(marin_text)\n",
    "len(marin_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b128347b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank',\n",
       " 'you',\n",
       " 'and',\n",
       " 'most',\n",
       " 'importantly',\n",
       " 'my',\n",
       " 'warmest',\n",
       " 'congratulations',\n",
       " 'to',\n",
       " 'the']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postpunc_marin = []\n",
    "punctuation = re.compile(r'[-._?!,:;’”()“–|0-9]')\n",
    "for words in marin_tokens:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word) > 0:\n",
    "        postpunc_marin.append(word.lower())\n",
    "postpunc_marin[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "918044b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank',\n",
       " 'importantly',\n",
       " 'warmest',\n",
       " 'congratulations',\n",
       " 'magnificent',\n",
       " 'graduating',\n",
       " 'class',\n",
       " 'new',\n",
       " 'york',\n",
       " 'university']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Words like \"New York\" and \"United States\" were treated as different words... I don't know how to fix this, but it is \n",
    "#something that should be taken into account.\n",
    "filtered_marin = [w for w in postpunc_marin if not w.lower() in stop_words]\n",
    "filtered_marin[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9b8d763e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('change', 19),\n",
       " ('want', 13),\n",
       " ('world', 12),\n",
       " ('wanted', 12),\n",
       " ('things', 11),\n",
       " ('also', 9),\n",
       " ('today', 8),\n",
       " ('advice', 8),\n",
       " ('people', 8),\n",
       " ('fear', 8),\n",
       " ('class', 7),\n",
       " ('new', 7),\n",
       " ('one', 7),\n",
       " ('take', 7),\n",
       " ('climate', 7),\n",
       " ('see', 7),\n",
       " ('need', 7),\n",
       " ('day', 6),\n",
       " ('enough', 6),\n",
       " ('freedom', 6),\n",
       " ('many', 5),\n",
       " ('might', 5),\n",
       " ('know', 5),\n",
       " ('biodiversity', 5),\n",
       " ('gender', 5),\n",
       " ('everyone', 5),\n",
       " ('future', 5),\n",
       " ('make', 5),\n",
       " ('would', 4),\n",
       " ('dear', 4),\n",
       " ('thought', 4),\n",
       " ('first', 4),\n",
       " ('question', 4),\n",
       " ('responsibility', 4),\n",
       " ('loss', 4),\n",
       " ('rights', 4),\n",
       " ('sure', 4),\n",
       " ('equal', 4),\n",
       " ('sustainable', 4),\n",
       " ('changes', 4),\n",
       " ('values', 4),\n",
       " ('artificial', 4),\n",
       " ('intelligence', 4),\n",
       " ('way', 4),\n",
       " ('importantly', 3),\n",
       " ('york', 3),\n",
       " ('nyu', 3),\n",
       " ('like', 3),\n",
       " ('family', 3),\n",
       " ('share', 3)]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistmarin = FreqDist(filtered_marin) \n",
    "marin_list = fdistmarin.most_common(50)\n",
    "marin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "cc8e48a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>change</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wanted</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>things</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>also</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>today</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>advice</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>people</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fear</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  frequency\n",
       "0  change         19\n",
       "1    want         13\n",
       "2   world         12\n",
       "3  wanted         12\n",
       "4  things         11\n",
       "5    also          9\n",
       "6   today          8\n",
       "7  advice          8\n",
       "8  people          8\n",
       "9    fear          8"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_marin = pd.DataFrame(marin_list, columns=['word', 'frequency'])\n",
    "df_marin[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a014796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marin.to_csv(r'marintop50n.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ade1c4",
   "metadata": {},
   "source": [
    "### Patton Oswalt - William and Mary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "34c095ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "oswalt_text = \"\"\"I just wanted to say to the to the  president to the administration  five words which is a \"thank you for this  privilege\" and to my teachers, my professors  who I had then and to the professors  here now, I say four words \"I cherish your guidance\"  and to the graduating class of 2023,  I say three words... \"you poor bastards\" [Applause]  Thank you... okay... um listen don't think of me as your  commencement speaker right now, think of me  as your shift manager at the Walmart all right?  I'm your shift manager. Now most days you come into  work and before I send you out under the floor I  sling a little pep talk at you and I go \"hey you  know let's get the Halloween stuff up in aisle four and five\" or \"oh someone dropped a bottle of  ranch dressing near the sporting goods let's get  that mopped up\" all right? Typical normal days with  typical normal tasks that I know you or anyone can  handle all right and if I'd given this speech back  in 2013 it would have been an equivalent of  that pre-shift pep talk that I gave right now  Right? Yeah there's problems out there nothing you  can't handle up an atom. Today's pre-shift pep talk  it's going to be a little different because first  off, a tornado has ripped the roof off the storeand right after that an  18-wheeler full of rabid possums  crashed through the wall in  the sporting goods section  and now there are rabid possums with hockey sticks  and air rifles and for some reason all the possums  are white nationalists I don't know how this is  happening but that's what's going on all right?  And in the face of all of this disaster, for some  reason I'm still giving you tasks like uh there's  two new flavors of potato chips so make sure  they're visible when the shoppers enter the store or stock the outdoor grill supplies because  Fourth of July is right around the corner   just aggressively ignoring the tornado and the white  nationalist possums just pretending like it's a  normal day and you can tell by the way that I'm  talking to you that my brain has completely broken  and I cannot handle it. I've retreated to potato  chips and grill supplies will fix everything LMAObut we know it won't because here's the  hard truth, the reason that the tornado  was able to rip the roof off the store  in the first place is because while I  and the management before me was supposed  to be scheduling roof inspections we were  metaphorically sucking the nitrous out of  the ready whip cans in the grocery sectionand the reason that the rabid raccoon... the  Rabid possums are loose and armed and white  supremacists are because over at the  raccoon lab the scientists got bored  and gave the raccoons rabies and guns  because they thought it would be ironicYour concerns as you stumble out into reality  tomorrow are massive. Democracy is crumblingTruth is up for grabs. The planet's trying to kill us,  and loneliness is driving everyone insane. okay umlet's hear it for the nihilists out there huh yeahto let you know how far we've come I want to give  you a quick glimpse at what mattered to me my  senior year in 1991. I took a class called Physics  for Poets. Do they still have that class here no?  Well they had a class called Physics for Poets  and the class was offered to get dainty English majorslike me our science credit and they made  physics and mathematics very AP English friendly  so all of us little poetry fans could go in there  and go \"is the red planet Mars like the Crimson eyeof Cerberus\" yeah whatever sit down let's just  get you your C plus and get you out of hereand are the professor that taught this class,  openly hated us hated all of us. He was doing  a favor for the school. He was not happy  to be teaching us little daffodils but he  soldiered through and got it done. For the  finals, in an attempt to reach out to us  he sprinkled a little AP English dust on the final  exam questions and one of them was a word problem  and he wrote it on the board and the word problem  was the USS Enterprise is traveling through space  a Romulan ship is approaching the USS  Enterprise. Kirk tells Chekhov to fire the phasers. If the phasers leave the Enterprise  going at this speed and the Romulan ship is  coming at this speed it was basically  a distance in motion problem in space  so we're all in the auditorium and we're doing the  exam and my friend who was sitting next to mehe remembers it to this day, he said in the middle  of the exam you stood up you walked down to the  professor and you said we couldn't hear what you  were saying but it was very pointed and it was  very angry and then you walk back to your seat  and the professor's head just dropped and then  he stood up and he said I've just been informed  that Sulu fires the phasers on the USS Enterpriseif this made the problem impossible to solve  I will change the name of the crew member  please turn in your blue book so I'm going to go  home and drink myself to death. I hate all of you  I hope you all die of whatever  killed Lord Byron goodbye I'm doneThat's what I was concerned with. That was my biggest concern.I basically breezed into a world full of trivia and silliness  and fun you are about to enter a hellscape  where you will have to fight for every  scrap of your humanity and dignityand I literally I literally wrote  down say something positive here LOLthis is wait a minute this is the positive thing  I'm a comedian I'll get out of this  hole. Watch this. This will be amazingYou do not have a choice but to be anything  but extraordinary that is that those are the  times you're living in right now and it's  been amazing it's been truly amazing to  see how your generation has rebelled against  every bad habit of mine and every generation  that came before me. Everything that we let  calcify you have kicked against and demolished  You've rejected that whole 24/7 no days off  grind you've re you've rejected apathy you've  rejected ignoring your mental health because  she got a muscle through it no matter whatyou've rejected alienation and cruelty you've  rejected not trying to include everyone and you've  rejected not looking out for each other and those  are hard things to reject because accepting them  sometimes makes life way easier. If you just  shut off yourself from the world, life is way easier. It's also way less colorful. It's way  less complicated, way less nourishing and way less memorableand despite all of the callousness  and violence that gets beamed out seemingly from  every screen big and small every second of the day  there are as many if not more people and most of  them are your age and younger that are beaming  out understanding and forgiveness and honesty.  It's stunning to see it. It's truly stunning  to see what you guys are standing up againstSometimes you guys are capable of a level of  radical empathy that accepts people who have let  loneliness poison them to the point where they've  armored themselves with hatred and fear and you're  the first generation that's truly grasped the  Gerald Kirsch phrase \"there are certain men you  despise until you glimpse through a crack in their  armor something nailed down and writhing in pain\"  My generation with a few amazing exceptions  wasn't really good at seeing through those  cracks and the fear armor and the generation  before us was even less adept but you guys get  it and you are passing it forward and again  it is encouraging and it's amazing and it's energizing.So thank you! Thank you every single  day for what you stand against and for what  you reject and when I say that I mean all of  you and I meant that in the videoI want to thank the administration for having a 2.8  GPA alumni come to speak this year, all right?And I want to say something to the 4.0 students  and by the way it's it's amazing the work that  you've done but every now and then take a  note from the 2.8s and the 3.1s all right?  Take a lead from the daydreamers and the confused  and the seekers. Obviously you should work hard  and play hard but you should also wander easy, all  right? And by the way in the spirit of my 2.8 GPA  the last two pages of my speech I finished an hour  before I gave this. I did this in my hotel room soEverything extraordinary in my life came from the  wandering and that's not to say I didn't work hard  and that you shouldn't work hard but don't work  hard to acquire things. Work hard so that you can  buy yourself the time to wander easy, use whatever  skills you have to carve out days of randomness  and adventure because there are people out there  and they've always been out there just these days  they're louder and they have more toys to amplify  their voice with but there are people out there  who want to manage every moment they want to  divvy up every dream and they want to commodify  every crazy creative caprice that springs out  of your cranium. Don't let them. Be human in all  of its bedlam and beauty and madness and mercy  for as long as you can and in any way you can.  I will now conclude my remarks with  a quote from the movie Blade RunnerI assume most of you have  seen the movie Blade Runner  wonderful 1982 film directed by Ridley Scott. It's about androids who crave life and crave humanity  but only have four years to live. Harrison Ford  plays a guy who hunts them down and kills themand at the end of the movie there's this  amazing speech that's given by the actor  Rutger Howard the late actor Rutger Hower where  he's about to die that his android's about to die  and he says \"I've seen things you people  wouldn't believe. I've seen attack ships  on fire off the shoulder of Orion. I've seen C-beams glitter in the dark near the Tannhauser gate.  All of these moments will be lost in time like tears in rain. Time to die\" and the reason  that I brought that speech up is because it...  trusts me I will get out of this hole. Watch!  because in that movie which at the time was The  cutting edge of technology was the cutting edge of  inhumanity and over planning and over scheduling.  Every single word of dialogue was mapped out that  speech was thought up the day they were shooting  it by the actor himself they didn't know how to  end the movie and they let chaos and creativity  and humanity punch through and it made the most  memorable scene in a movie about androids with  no Humanity that is the wandering and the chaos  and the madness that you have to seek out so what  I say to all of you is that \"I've seen things you  people wouldn't believe. I've seen porta-potties  on fire from a helicopter above Woodstock 99.  I've seen I've seen Charlize Theron glitter in  the dark from the backstage wings of the Oscars  All of these moments and far better  ones are waiting to be experienced  and marveled at by every one of you.  It's time to live. Thank you [Applause]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "567d1388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2144"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oswalt_tokens = word_tokenize(oswalt_text)\n",
    "len(oswalt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f8bf915f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'just', 'wanted', 'to', 'say', 'to', 'the', 'to', 'the', 'president']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postpunc_oswalt = []\n",
    "punctuation = re.compile(r'[-._?``!'',:;’”()“–|0-9]')\n",
    "for words in oswalt_tokens:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word) > 0:\n",
    "        postpunc_oswalt.append(word.lower())\n",
    "postpunc_oswalt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "27552441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wanted',\n",
       " 'say',\n",
       " 'president',\n",
       " 'administration',\n",
       " 'five',\n",
       " 'words',\n",
       " 'thank',\n",
       " 'privilege',\n",
       " \"''\",\n",
       " 'teachers']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_oswalt = [w for w in postpunc_oswalt if not w.lower() in stop_words]\n",
    "filtered_oswalt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0642457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'s\", 33),\n",
       " (\"'ve\", 20),\n",
       " (\"n't\", 13),\n",
       " ('right', 13),\n",
       " ('every', 12),\n",
       " ('way', 10),\n",
       " ('say', 8),\n",
       " (\"''\", 8),\n",
       " ('let', 8),\n",
       " ('get', 8),\n",
       " ('hard', 8),\n",
       " ('seen', 8),\n",
       " ('work', 7),\n",
       " ('us', 7),\n",
       " ('thank', 6),\n",
       " ('class', 6),\n",
       " (\"'m\", 6),\n",
       " ('know', 6),\n",
       " (\"'re\", 6),\n",
       " ('want', 6),\n",
       " ('amazing', 6),\n",
       " ('rejected', 6),\n",
       " ('people', 6),\n",
       " ('movie', 6),\n",
       " ('days', 5),\n",
       " ('little', 5),\n",
       " ('speech', 5),\n",
       " ('possums', 5),\n",
       " ('reason', 5),\n",
       " ('day', 5),\n",
       " ('generation', 5),\n",
       " ('less', 5),\n",
       " ('time', 5),\n",
       " ('go', 4),\n",
       " ('would', 4),\n",
       " ('going', 4),\n",
       " ('rabid', 4),\n",
       " ('like', 4),\n",
       " ('problem', 4),\n",
       " ('die', 4),\n",
       " ('humanity', 4),\n",
       " ('things', 4),\n",
       " ('life', 4),\n",
       " ('words', 3),\n",
       " ('four', 3),\n",
       " ('come', 3),\n",
       " ('pep', 3),\n",
       " ('talk', 3),\n",
       " ('normal', 3),\n",
       " ('handle', 3)]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistoswalt = FreqDist(filtered_oswalt) \n",
    "fdistoswalt.most_common(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "00548001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wanted',\n",
       " 'say',\n",
       " 'president',\n",
       " 'administration',\n",
       " 'five',\n",
       " 'words',\n",
       " 'thank',\n",
       " 'privilege',\n",
       " 'teachers',\n",
       " 'professors',\n",
       " 'professors',\n",
       " 'say',\n",
       " 'four',\n",
       " 'words',\n",
       " 'cherish',\n",
       " 'guidance',\n",
       " 'graduating',\n",
       " 'class',\n",
       " 'say',\n",
       " 'three',\n",
       " 'words',\n",
       " 'poor',\n",
       " 'bastards',\n",
       " 'thank',\n",
       " 'okay',\n",
       " 'um',\n",
       " 'listen',\n",
       " 'think',\n",
       " 'commencement',\n",
       " 'speaker',\n",
       " 'right',\n",
       " 'think',\n",
       " 'shift',\n",
       " 'manager',\n",
       " 'walmart',\n",
       " 'right',\n",
       " 'shift',\n",
       " 'manager',\n",
       " 'days',\n",
       " 'come',\n",
       " 'work',\n",
       " 'send',\n",
       " 'floor',\n",
       " 'sling',\n",
       " 'little',\n",
       " 'pep',\n",
       " 'talk',\n",
       " 'go',\n",
       " 'hey',\n",
       " 'know',\n",
       " 'let',\n",
       " 'get',\n",
       " 'halloween',\n",
       " 'stuff',\n",
       " 'aisle',\n",
       " 'four',\n",
       " 'five',\n",
       " 'oh',\n",
       " 'someone',\n",
       " 'dropped',\n",
       " 'bottle',\n",
       " 'ranch',\n",
       " 'dressing',\n",
       " 'near',\n",
       " 'sporting',\n",
       " 'goods',\n",
       " 'let',\n",
       " 'get',\n",
       " 'mopped',\n",
       " 'right',\n",
       " 'typical',\n",
       " 'normal',\n",
       " 'days',\n",
       " 'typical',\n",
       " 'normal',\n",
       " 'tasks',\n",
       " 'know',\n",
       " 'anyone',\n",
       " 'handle',\n",
       " 'right',\n",
       " 'given',\n",
       " 'speech',\n",
       " 'back',\n",
       " 'would',\n",
       " 'equivalent',\n",
       " 'preshift',\n",
       " 'pep',\n",
       " 'talk',\n",
       " 'gave',\n",
       " 'right',\n",
       " 'right',\n",
       " 'yeah',\n",
       " 'problems',\n",
       " 'nothing',\n",
       " 'handle',\n",
       " 'atom',\n",
       " 'today',\n",
       " 'preshift',\n",
       " 'pep',\n",
       " 'talk',\n",
       " 'going',\n",
       " 'little',\n",
       " 'different',\n",
       " 'first',\n",
       " 'tornado',\n",
       " 'ripped',\n",
       " 'roof',\n",
       " 'storeand',\n",
       " 'right',\n",
       " 'wheeler',\n",
       " 'full',\n",
       " 'rabid',\n",
       " 'possums',\n",
       " 'crashed',\n",
       " 'wall',\n",
       " 'sporting',\n",
       " 'goods',\n",
       " 'section',\n",
       " 'rabid',\n",
       " 'possums',\n",
       " 'hockey',\n",
       " 'sticks',\n",
       " 'air',\n",
       " 'rifles',\n",
       " 'reason',\n",
       " 'possums',\n",
       " 'white',\n",
       " 'nationalists',\n",
       " 'know',\n",
       " 'happening',\n",
       " 'going',\n",
       " 'right',\n",
       " 'face',\n",
       " 'disaster',\n",
       " 'reason',\n",
       " 'still',\n",
       " 'giving',\n",
       " 'tasks',\n",
       " 'like',\n",
       " 'uh',\n",
       " 'two',\n",
       " 'new',\n",
       " 'flavors',\n",
       " 'potato',\n",
       " 'chips',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'visible',\n",
       " 'shoppers',\n",
       " 'enter',\n",
       " 'store',\n",
       " 'stock',\n",
       " 'outdoor',\n",
       " 'grill',\n",
       " 'supplies',\n",
       " 'fourth',\n",
       " 'july',\n",
       " 'right',\n",
       " 'around',\n",
       " 'corner',\n",
       " 'aggressively',\n",
       " 'ignoring',\n",
       " 'tornado',\n",
       " 'white',\n",
       " 'nationalist',\n",
       " 'possums',\n",
       " 'pretending',\n",
       " 'like',\n",
       " 'normal',\n",
       " 'day',\n",
       " 'tell',\n",
       " 'way',\n",
       " 'talking',\n",
       " 'brain',\n",
       " 'completely',\n",
       " 'broken',\n",
       " 'handle',\n",
       " 'retreated',\n",
       " 'potato',\n",
       " 'chips',\n",
       " 'grill',\n",
       " 'supplies',\n",
       " 'fix',\n",
       " 'everything',\n",
       " 'lmaobut',\n",
       " 'know',\n",
       " 'wo',\n",
       " 'hard',\n",
       " 'truth',\n",
       " 'reason',\n",
       " 'tornado',\n",
       " 'able',\n",
       " 'rip',\n",
       " 'roof',\n",
       " 'store',\n",
       " 'first',\n",
       " 'place',\n",
       " 'management',\n",
       " 'supposed',\n",
       " 'scheduling',\n",
       " 'roof',\n",
       " 'inspections',\n",
       " 'metaphorically',\n",
       " 'sucking',\n",
       " 'nitrous',\n",
       " 'ready',\n",
       " 'whip',\n",
       " 'cans',\n",
       " 'grocery',\n",
       " 'sectionand',\n",
       " 'reason',\n",
       " 'rabid',\n",
       " 'raccoon',\n",
       " 'rabid',\n",
       " 'possums',\n",
       " 'loose',\n",
       " 'armed',\n",
       " 'white',\n",
       " 'supremacists',\n",
       " 'raccoon',\n",
       " 'lab',\n",
       " 'scientists',\n",
       " 'got',\n",
       " 'bored',\n",
       " 'gave',\n",
       " 'raccoons',\n",
       " 'rabies',\n",
       " 'guns',\n",
       " 'thought',\n",
       " 'would',\n",
       " 'ironicyour',\n",
       " 'concerns',\n",
       " 'stumble',\n",
       " 'reality',\n",
       " 'tomorrow',\n",
       " 'massive',\n",
       " 'democracy',\n",
       " 'crumblingtruth',\n",
       " 'grabs',\n",
       " 'planet',\n",
       " 'trying',\n",
       " 'kill',\n",
       " 'us',\n",
       " 'loneliness',\n",
       " 'driving',\n",
       " 'everyone',\n",
       " 'insane',\n",
       " 'okay',\n",
       " 'umlet',\n",
       " 'hear',\n",
       " 'nihilists',\n",
       " 'huh',\n",
       " 'yeahto',\n",
       " 'let',\n",
       " 'know',\n",
       " 'far',\n",
       " 'come',\n",
       " 'want',\n",
       " 'give',\n",
       " 'quick',\n",
       " 'glimpse',\n",
       " 'mattered',\n",
       " 'senior',\n",
       " 'year',\n",
       " 'took',\n",
       " 'class',\n",
       " 'called',\n",
       " 'physics',\n",
       " 'poets',\n",
       " 'still',\n",
       " 'class',\n",
       " 'well',\n",
       " 'class',\n",
       " 'called',\n",
       " 'physics',\n",
       " 'poets',\n",
       " 'class',\n",
       " 'offered',\n",
       " 'get',\n",
       " 'dainty',\n",
       " 'english',\n",
       " 'majorslike',\n",
       " 'science',\n",
       " 'credit',\n",
       " 'made',\n",
       " 'physics',\n",
       " 'mathematics',\n",
       " 'ap',\n",
       " 'english',\n",
       " 'friendly',\n",
       " 'us',\n",
       " 'little',\n",
       " 'poetry',\n",
       " 'fans',\n",
       " 'could',\n",
       " 'go',\n",
       " 'go',\n",
       " 'red',\n",
       " 'planet',\n",
       " 'mars',\n",
       " 'like',\n",
       " 'crimson',\n",
       " 'eyeof',\n",
       " 'cerberus',\n",
       " 'yeah',\n",
       " 'whatever',\n",
       " 'sit',\n",
       " 'let',\n",
       " 'get',\n",
       " 'c',\n",
       " 'plus',\n",
       " 'get',\n",
       " 'hereand',\n",
       " 'professor',\n",
       " 'taught',\n",
       " 'class',\n",
       " 'openly',\n",
       " 'hated',\n",
       " 'us',\n",
       " 'hated',\n",
       " 'us',\n",
       " 'favor',\n",
       " 'school',\n",
       " 'happy',\n",
       " 'teaching',\n",
       " 'us',\n",
       " 'little',\n",
       " 'daffodils',\n",
       " 'soldiered',\n",
       " 'got',\n",
       " 'done',\n",
       " 'finals',\n",
       " 'attempt',\n",
       " 'reach',\n",
       " 'us',\n",
       " 'sprinkled',\n",
       " 'little',\n",
       " 'ap',\n",
       " 'english',\n",
       " 'dust',\n",
       " 'final',\n",
       " 'exam',\n",
       " 'questions',\n",
       " 'one',\n",
       " 'word',\n",
       " 'problem',\n",
       " 'wrote',\n",
       " 'board',\n",
       " 'word',\n",
       " 'problem',\n",
       " 'uss',\n",
       " 'enterprise',\n",
       " 'traveling',\n",
       " 'space',\n",
       " 'romulan',\n",
       " 'ship',\n",
       " 'approaching',\n",
       " 'uss',\n",
       " 'enterprise',\n",
       " 'kirk',\n",
       " 'tells',\n",
       " 'chekhov',\n",
       " 'fire',\n",
       " 'phasers',\n",
       " 'phasers',\n",
       " 'leave',\n",
       " 'enterprise',\n",
       " 'going',\n",
       " 'speed',\n",
       " 'romulan',\n",
       " 'ship',\n",
       " 'coming',\n",
       " 'speed',\n",
       " 'basically',\n",
       " 'distance',\n",
       " 'motion',\n",
       " 'problem',\n",
       " 'space',\n",
       " 'auditorium',\n",
       " 'exam',\n",
       " 'friend',\n",
       " 'sitting',\n",
       " 'next',\n",
       " 'mehe',\n",
       " 'remembers',\n",
       " 'day',\n",
       " 'said',\n",
       " 'middle',\n",
       " 'exam',\n",
       " 'stood',\n",
       " 'walked',\n",
       " 'professor',\n",
       " 'said',\n",
       " 'could',\n",
       " 'hear',\n",
       " 'saying',\n",
       " 'pointed',\n",
       " 'angry',\n",
       " 'walk',\n",
       " 'back',\n",
       " 'seat',\n",
       " 'professor',\n",
       " 'head',\n",
       " 'dropped',\n",
       " 'stood',\n",
       " 'said',\n",
       " 'informed',\n",
       " 'sulu',\n",
       " 'fires',\n",
       " 'phasers',\n",
       " 'uss',\n",
       " 'enterpriseif',\n",
       " 'made',\n",
       " 'problem',\n",
       " 'impossible',\n",
       " 'solve',\n",
       " 'change',\n",
       " 'name',\n",
       " 'crew',\n",
       " 'member',\n",
       " 'please',\n",
       " 'turn',\n",
       " 'blue',\n",
       " 'book',\n",
       " 'going',\n",
       " 'go',\n",
       " 'home',\n",
       " 'drink',\n",
       " 'death',\n",
       " 'hate',\n",
       " 'hope',\n",
       " 'die',\n",
       " 'whatever',\n",
       " 'killed',\n",
       " 'lord',\n",
       " 'byron',\n",
       " 'goodbye',\n",
       " 'donethat',\n",
       " 'concerned',\n",
       " 'biggest',\n",
       " 'concerni',\n",
       " 'basically',\n",
       " 'breezed',\n",
       " 'world',\n",
       " 'full',\n",
       " 'trivia',\n",
       " 'silliness',\n",
       " 'fun',\n",
       " 'enter',\n",
       " 'hellscape',\n",
       " 'fight',\n",
       " 'every',\n",
       " 'scrap',\n",
       " 'humanity',\n",
       " 'dignityand',\n",
       " 'literally',\n",
       " 'literally',\n",
       " 'wrote',\n",
       " 'say',\n",
       " 'something',\n",
       " 'positive',\n",
       " 'lolthis',\n",
       " 'wait',\n",
       " 'minute',\n",
       " 'positive',\n",
       " 'thing',\n",
       " 'comedian',\n",
       " 'get',\n",
       " 'hole',\n",
       " 'watch',\n",
       " 'amazingyou',\n",
       " 'choice',\n",
       " 'anything',\n",
       " 'extraordinary',\n",
       " 'times',\n",
       " 'living',\n",
       " 'right',\n",
       " 'amazing',\n",
       " 'truly',\n",
       " 'amazing',\n",
       " 'see',\n",
       " 'generation',\n",
       " 'rebelled',\n",
       " 'every',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'mine',\n",
       " 'every',\n",
       " 'generation',\n",
       " 'came',\n",
       " 'everything',\n",
       " 'let',\n",
       " 'calcify',\n",
       " 'kicked',\n",
       " 'demolished',\n",
       " 'rejected',\n",
       " 'whole',\n",
       " '/',\n",
       " 'days',\n",
       " 'grind',\n",
       " 'rejected',\n",
       " 'apathy',\n",
       " 'rejected',\n",
       " 'ignoring',\n",
       " 'mental',\n",
       " 'health',\n",
       " 'got',\n",
       " 'muscle',\n",
       " 'matter',\n",
       " 'whatyou',\n",
       " 'rejected',\n",
       " 'alienation',\n",
       " 'cruelty',\n",
       " 'rejected',\n",
       " 'trying',\n",
       " 'include',\n",
       " 'everyone',\n",
       " 'rejected',\n",
       " 'looking',\n",
       " 'hard',\n",
       " 'things',\n",
       " 'reject',\n",
       " 'accepting',\n",
       " 'sometimes',\n",
       " 'makes',\n",
       " 'life',\n",
       " 'way',\n",
       " 'easier',\n",
       " 'shut',\n",
       " 'world',\n",
       " 'life',\n",
       " 'way',\n",
       " 'easier',\n",
       " 'also',\n",
       " 'way',\n",
       " 'less',\n",
       " 'colorful',\n",
       " 'way',\n",
       " 'less',\n",
       " 'complicated',\n",
       " 'way',\n",
       " 'less',\n",
       " 'nourishing',\n",
       " 'way',\n",
       " 'less',\n",
       " 'memorableand',\n",
       " 'despite',\n",
       " 'callousness',\n",
       " 'violence',\n",
       " 'gets',\n",
       " 'beamed',\n",
       " 'seemingly',\n",
       " 'every',\n",
       " 'screen',\n",
       " 'big',\n",
       " 'small',\n",
       " 'every',\n",
       " 'second',\n",
       " 'day',\n",
       " 'many',\n",
       " 'people',\n",
       " 'age',\n",
       " 'younger',\n",
       " 'beaming',\n",
       " 'understanding',\n",
       " 'forgiveness',\n",
       " 'honesty',\n",
       " 'stunning',\n",
       " 'see',\n",
       " 'truly',\n",
       " 'stunning',\n",
       " 'see',\n",
       " 'guys',\n",
       " 'standing',\n",
       " 'againstsometimes',\n",
       " 'guys',\n",
       " 'capable',\n",
       " 'level',\n",
       " 'radical',\n",
       " 'empathy',\n",
       " 'accepts',\n",
       " 'people',\n",
       " 'let',\n",
       " 'loneliness',\n",
       " 'poison',\n",
       " 'point',\n",
       " 'armored',\n",
       " 'hatred',\n",
       " 'fear',\n",
       " 'first',\n",
       " 'generation',\n",
       " 'truly',\n",
       " 'grasped',\n",
       " 'gerald',\n",
       " 'kirsch',\n",
       " 'phrase',\n",
       " 'certain',\n",
       " 'men',\n",
       " 'despise',\n",
       " 'glimpse',\n",
       " 'crack',\n",
       " 'armor',\n",
       " 'something',\n",
       " 'nailed',\n",
       " 'writhing',\n",
       " 'pain',\n",
       " 'generation',\n",
       " 'amazing',\n",
       " 'exceptions',\n",
       " 'really',\n",
       " 'good',\n",
       " 'seeing',\n",
       " 'cracks',\n",
       " 'fear',\n",
       " 'armor',\n",
       " 'generation',\n",
       " 'us',\n",
       " 'even',\n",
       " 'less',\n",
       " 'adept',\n",
       " 'guys',\n",
       " 'get',\n",
       " 'passing',\n",
       " 'forward',\n",
       " 'encouraging',\n",
       " 'amazing',\n",
       " 'energizingso',\n",
       " 'thank',\n",
       " 'thank',\n",
       " 'every',\n",
       " 'single',\n",
       " 'day',\n",
       " 'stand',\n",
       " 'reject',\n",
       " 'say',\n",
       " 'mean',\n",
       " 'meant',\n",
       " 'videoi',\n",
       " 'want',\n",
       " 'thank',\n",
       " 'administration',\n",
       " 'gpa',\n",
       " 'alumni',\n",
       " 'come',\n",
       " 'speak',\n",
       " 'year',\n",
       " 'right',\n",
       " 'want',\n",
       " 'say',\n",
       " 'something',\n",
       " 'students',\n",
       " 'way',\n",
       " 'amazing',\n",
       " 'work',\n",
       " 'done',\n",
       " 'every',\n",
       " 'take',\n",
       " 'note',\n",
       " 'right',\n",
       " 'take',\n",
       " 'lead',\n",
       " 'daydreamers',\n",
       " 'confused',\n",
       " 'seekers',\n",
       " 'obviously',\n",
       " 'work',\n",
       " 'hard',\n",
       " 'play',\n",
       " 'hard',\n",
       " 'also',\n",
       " 'wander',\n",
       " 'easy',\n",
       " 'right',\n",
       " 'way',\n",
       " 'spirit',\n",
       " 'gpa',\n",
       " 'last',\n",
       " 'two',\n",
       " 'pages',\n",
       " 'speech',\n",
       " 'finished',\n",
       " 'hour',\n",
       " 'gave',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'soeverything',\n",
       " 'extraordinary',\n",
       " 'life',\n",
       " 'came',\n",
       " 'wandering',\n",
       " 'say',\n",
       " 'work',\n",
       " 'hard',\n",
       " 'work',\n",
       " 'hard',\n",
       " 'work',\n",
       " 'hard',\n",
       " 'acquire',\n",
       " 'things',\n",
       " 'work',\n",
       " 'hard',\n",
       " 'buy',\n",
       " 'time',\n",
       " 'wander',\n",
       " 'easy',\n",
       " 'use',\n",
       " 'whatever',\n",
       " 'skills',\n",
       " 'carve',\n",
       " 'days',\n",
       " 'randomness',\n",
       " 'adventure',\n",
       " 'people',\n",
       " 'always',\n",
       " 'days',\n",
       " 'louder',\n",
       " 'toys',\n",
       " 'amplify',\n",
       " 'voice',\n",
       " 'people',\n",
       " 'want',\n",
       " 'manage',\n",
       " 'every',\n",
       " 'moment',\n",
       " 'want',\n",
       " 'divvy',\n",
       " 'every',\n",
       " 'dream',\n",
       " 'want',\n",
       " 'commodify',\n",
       " 'every',\n",
       " 'crazy',\n",
       " 'creative',\n",
       " 'caprice',\n",
       " 'springs',\n",
       " 'cranium',\n",
       " 'let',\n",
       " 'human',\n",
       " 'bedlam',\n",
       " 'beauty',\n",
       " 'madness',\n",
       " 'mercy',\n",
       " 'long',\n",
       " 'way',\n",
       " 'conclude',\n",
       " 'remarks',\n",
       " 'quote',\n",
       " 'movie',\n",
       " 'blade',\n",
       " 'runneri',\n",
       " 'assume',\n",
       " 'seen',\n",
       " 'movie',\n",
       " 'blade',\n",
       " 'runner',\n",
       " 'wonderful',\n",
       " 'film',\n",
       " 'directed',\n",
       " 'ridley',\n",
       " 'scott',\n",
       " 'androids',\n",
       " 'crave',\n",
       " 'life',\n",
       " 'crave',\n",
       " 'humanity',\n",
       " 'four',\n",
       " 'years',\n",
       " 'live',\n",
       " 'harrison',\n",
       " 'ford',\n",
       " 'plays',\n",
       " 'guy',\n",
       " 'hunts',\n",
       " 'kills',\n",
       " 'themand',\n",
       " 'end',\n",
       " 'movie',\n",
       " 'amazing',\n",
       " 'speech',\n",
       " 'given',\n",
       " 'actor',\n",
       " 'rutger',\n",
       " 'howard',\n",
       " 'late',\n",
       " 'actor',\n",
       " 'rutger',\n",
       " 'hower',\n",
       " 'die',\n",
       " 'android',\n",
       " 'die',\n",
       " 'says',\n",
       " 'seen',\n",
       " 'things',\n",
       " 'people',\n",
       " 'would',\n",
       " 'believe',\n",
       " 'seen',\n",
       " 'attack',\n",
       " 'ships',\n",
       " 'fire',\n",
       " 'shoulder',\n",
       " 'orion',\n",
       " 'seen',\n",
       " 'cbeams',\n",
       " 'glitter',\n",
       " 'dark',\n",
       " 'near',\n",
       " 'tannhauser',\n",
       " 'gate',\n",
       " 'moments',\n",
       " 'lost',\n",
       " 'time',\n",
       " 'like',\n",
       " 'tears',\n",
       " 'rain',\n",
       " 'time',\n",
       " 'die',\n",
       " 'reason',\n",
       " 'brought',\n",
       " 'speech',\n",
       " 'trusts',\n",
       " 'get',\n",
       " 'hole',\n",
       " 'watch',\n",
       " 'movie',\n",
       " 'time',\n",
       " 'cutting',\n",
       " 'edge',\n",
       " 'technology',\n",
       " 'cutting',\n",
       " 'edge',\n",
       " 'inhumanity',\n",
       " 'planning',\n",
       " 'scheduling',\n",
       " 'every',\n",
       " 'single',\n",
       " 'word',\n",
       " 'dialogue',\n",
       " 'mapped',\n",
       " 'speech',\n",
       " 'thought',\n",
       " 'day',\n",
       " 'shooting',\n",
       " 'actor',\n",
       " 'know',\n",
       " 'end',\n",
       " 'movie',\n",
       " 'let',\n",
       " 'chaos',\n",
       " 'creativity',\n",
       " 'humanity',\n",
       " 'punch',\n",
       " 'made',\n",
       " 'memorable',\n",
       " 'scene',\n",
       " 'movie',\n",
       " 'androids',\n",
       " 'humanity',\n",
       " 'wandering',\n",
       " 'chaos',\n",
       " 'madness',\n",
       " 'seek',\n",
       " 'say',\n",
       " 'seen',\n",
       " 'things',\n",
       " 'people',\n",
       " 'would',\n",
       " 'believe',\n",
       " 'seen',\n",
       " 'portapotties',\n",
       " 'fire',\n",
       " 'helicopter',\n",
       " 'woodstock',\n",
       " 'seen',\n",
       " 'seen',\n",
       " 'charlize',\n",
       " 'theron',\n",
       " 'glitter',\n",
       " 'dark',\n",
       " 'backstage',\n",
       " 'wings',\n",
       " 'oscars',\n",
       " 'moments',\n",
       " 'far',\n",
       " 'better',\n",
       " 'ones',\n",
       " 'waiting',\n",
       " 'experienced',\n",
       " 'marveled',\n",
       " 'every',\n",
       " 'one',\n",
       " 'time',\n",
       " 'live',\n",
       " 'thank']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_words = [\"applause\", \"cheers\",\"'s\",\"'ll\", \"'d\", \"'ve\", \"n't\", \"[\", \"]\", \"ca\", \"'m\", \"''\", \"'re\"]\n",
    "oswalt_list = []\n",
    "for word in filtered_oswalt:\n",
    "    if word not in random_words:\n",
    "       oswalt_list.append(word)\n",
    "oswalt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "27ffcbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "oswalt_list2 = FreqDist(oswalt_list).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e8ee8894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>right</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>way</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>say</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>let</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  frequency\n",
       "0  right         13\n",
       "1  every         12\n",
       "2    way         10\n",
       "3    say          8\n",
       "4    let          8"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oswalt = pd.DataFrame(oswalt_list2, columns=['word', 'frequency'])\n",
    "df_oswalt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8301a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oswalt.to_csv(r'oswalttop50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db313acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
